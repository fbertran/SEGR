<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Chapitre 09. Inférence statistique. • SEGR</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Chapitre 09. Inférence statistique.">
<meta property="og:description" content="SEGR">
<meta property="og:image" content="https://fbertran.github.io/SEGR/reference/figures/logo.png">
<meta property="og:image:alt" content="Statistiques pour l’économie et la gestion">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:creator" content="@BertrandFrdric2">
<meta name="twitter:site" content="@deboeck">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">SEGR</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/CodeChap00Introduction.html">Avant-propos.</a>
    </li>
    <li>
      <a href="../articles/CodeChap01.html">Chapitre 01. Introduction à la statistique et à son environnement.</a>
    </li>
    <li>
      <a href="../articles/CodeChap02.html">Chapitre 02. Statistiques descriptives et visualisation des données univariables</a>
    </li>
    <li>
      <a href="../articles/CodeChap03.html">Chapitre 03.	Statistiques descriptives et visualisation des données bivariables ou multivariables</a>
    </li>
    <li>
      <a href="../articles/CodeChap04.html">Chapitre 04. Exploration de données avec l'analyse en composantes principales.</a>
    </li>
    <li>
      <a href="../articles/CodeChap05.html">Chapitre 05. Exploration de données avec l'analyse factorielle des correspondances.</a>
    </li>
    <li>
      <a href="../articles/CodeChap06.html">Chapitre 06. Exploration de données avec l'analyse des correspondances multiples.</a>
    </li>
    <li>
      <a href="../articles/CodeChap07.html">Chapitre 07. Exploration des données avec une classification automatique.</a>
    </li>
    <li>
      <a href="../articles/CodeChap08.html">Chapitre 08. Introduction à la théorie des probabilités aux distributions statistiques classiques.</a>
    </li>
    <li>
      <a href="../articles/CodeChap09.html">Chapitre 09. Inférence statistique.</a>
    </li>
    <li>
      <a href="../articles/CodeChap10.html">Chapitre 10. Modèle linéaire gaussien.</a>
    </li>
    <li>
      <a href="../articles/CodeChap11.html">Chapitre 11. Introduction aux séries temporelles.</a>
    </li>
    <li>
      <a href="../articles/CodeChap12.html">Chapitre 12. Introduction aux modèles logit et probit.</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/fbertran/SEGR/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="CodeChap09_files/header-attrs-2.6/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Chapitre 09. Inférence statistique.</h1>
            <h3 class="subtitle">Tout le code avec R. <img src="../man/figures/logo.png" align="right" width="200">
</h3>
                        <h4 class="author">F. Bertrand et M. Maumy</h4>
            
            <h4 class="date">2021-03-13</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/fbertran/SEGR/blob/master/vignettes/CodeChap09.Rmd"><code>vignettes/CodeChap09.Rmd</code></a></small>
      <div class="hidden name"><code>CodeChap09.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw">if</span><span class="op">(</span><span class="op">!</span><span class="op">(</span><span class="st">"SEGR"</span> <span class="op">%in%</span> <span class="fu"><a href="https://rdrr.io/r/utils/installed.packages.html">installed.packages</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"SEGR"</span><span class="op">)</span><span class="op">}</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://fbertran.github.io/homepage/">SEGR</a></span><span class="op">)</span></code></pre></div>
<div id="test-t-pour-deux-échantillons-indépendants-" class="section level1">
<h1 class="hasAnchor">
<a href="#test-t-pour-deux-%C3%A9chantillons-ind%C3%A9pendants-" class="anchor"></a>Test <span class="math inline">\(t\)</span> pour deux échantillons indépendants.</h1>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pipit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">17.0</span> , <span class="fl">16.9</span> , <span class="fl">16.9</span> , <span class="fl">17.3</span> , <span class="fl">16.8</span> , <span class="fl">16.8</span> , <span class="fl">17.0</span> , <span class="fl">16.5</span> , <span class="fl">16.9</span> , <span class="fl">16.5</span> , <span class="fl">17.0</span> , <span class="fl">17.0</span> , <span class="fl">16.8</span> , <span class="fl">17.0</span> , <span class="fl">16.9</span> , <span class="fl">17.0</span> , <span class="fl">17.0</span> , <span class="fl">17.3</span> , <span class="fl">16.8</span> , <span class="fl">17.1</span> , <span class="fl">16.9</span> , <span class="fl">16.8</span> , <span class="fl">17.1</span> , <span class="fl">17.0</span> , <span class="fl">17.1</span> , <span class="fl">17.2</span> , <span class="fl">16.7</span> , <span class="fl">16.6</span> , <span class="fl">17.2</span> , <span class="fl">17.0</span> , <span class="fl">17.0</span><span class="op">)</span>
<span class="va">fauvette</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">16.0</span> , <span class="fl">16.1</span> , <span class="fl">16.3</span> , <span class="fl">16.5</span> , <span class="fl">16.2</span> , <span class="fl">15.2</span> , <span class="fl">15.6</span> , <span class="fl">15.6</span> , <span class="fl">16.6</span> , <span class="fl">16.0</span> , <span class="fl">16.2</span> , <span class="fl">16.8</span> , <span class="fl">16.0</span> , <span class="fl">17.0</span> , <span class="fl">17.9</span> , <span class="fl">16.0</span> , <span class="fl">16.4</span> , <span class="fl">16.3</span> , <span class="fl">16.9</span> , <span class="fl">17.1</span> , <span class="fl">17.0</span> , <span class="fl">16.1</span> , <span class="fl">16.5</span> , <span class="fl">16.5</span> , <span class="fl">16.1</span> , <span class="fl">16.5</span> , <span class="fl">17.9</span> , <span class="fl">16.5</span> , <span class="fl">16.7</span> , <span class="fl">16.8</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test</a></span><span class="op">(</span><span class="va">pipit</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Shapiro-Wilk normality test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  pipit</span>
<span class="co">#&gt; W = 0.94442, p-value = 0.1094</span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test</a></span><span class="op">(</span><span class="va">fauvette</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Shapiro-Wilk normality test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  fauvette</span>
<span class="co">#&gt; W = 0.94926, p-value = 0.1615</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/var.test.html">var.test</a></span><span class="op">(</span><span class="va">pipit</span>,<span class="va">fauvette</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  F test to compare two variances</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  pipit and fauvette</span>
<span class="co">#&gt; F = 0.11195, num df = 30, denom df = 29, p-value = 4.767e-08</span>
<span class="co">#&gt; alternative hypothesis: true ratio of variances is not equal to 1</span>
<span class="co">#&gt; 95 percent confidence interval:</span>
<span class="co">#&gt;  0.05350369 0.23314689</span>
<span class="co">#&gt; sample estimates:</span>
<span class="co">#&gt; ratio of variances </span>
<span class="co">#&gt;          0.1119467</span></code></pre></div>
</div>
<div id="analyse-de-la-variance-à-un-facteur" class="section level1">
<h1 class="hasAnchor">
<a href="#analyse-de-la-variance-%C3%A0-un-facteur" class="anchor"></a>Analyse de la variance à un facteur</h1>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://fbertran.github.io/homepage/">SEGR</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">Marque.Valeur</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">Marque.Valeur</span><span class="op">)</span>
<span class="co">#&gt; 'data.frame':    90 obs. of  2 variables:</span>
<span class="co">#&gt;  $ Marque: Factor w/ 3 levels "Marque 1","Marque 2",..: 1 1 1 1 1 1 1 1 1 1 ...</span>
<span class="co">#&gt;  $ Valeur: num  1.5 1.95 1.84 1.08 1.28 2.07 -0.33 1.9 1.94 3.69 ...</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">Marque.Valeur.large</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">Marque.Valeur.large</span><span class="op">)</span>
<span class="co">#&gt; 'data.frame':    30 obs. of  3 variables:</span>
<span class="co">#&gt;  $ Marque.1: num  1.5 1.95 1.84 1.08 1.28 2.07 -0.33 1.9 1.94 3.69 ...</span>
<span class="co">#&gt;  $ Marque.2: num  1.98 1.86 3.3 2.19 3.43 2.49 1.98 2.84 4 3.13 ...</span>
<span class="co">#&gt;  $ Marque.3: num  4.46 6.49 4.69 3.23 4.53 3.61 3.45 2.91 4.25 4.12 ...</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">Marque.Valeur</span>,<span class="fu"><a href="https://rdrr.io/r/base/tapply.html">tapply</a></span><span class="op">(</span><span class="va">Valeur</span>,<span class="va">Marque</span>,<span class="va">mean</span><span class="op">)</span><span class="op">)</span>,<span class="fl">3</span><span class="op">)</span>
<span class="co">#&gt; Marque 1 Marque 2 Marque 3 </span>
<span class="co">#&gt;    1.411    2.889    4.124</span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">Marque.Valeur</span>,<span class="fu"><a href="https://rdrr.io/r/base/tapply.html">tapply</a></span><span class="op">(</span><span class="va">Valeur</span>,<span class="va">Marque</span>,<span class="va">sd</span><span class="op">)</span><span class="op">)</span>,<span class="fl">3</span><span class="op">)</span>
<span class="co">#&gt; Marque 1 Marque 2 Marque 3 </span>
<span class="co">#&gt;    0.870    1.051    0.939</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">Marque.Valeur</span>,<span class="fu"><a href="https://rdrr.io/r/base/tapply.html">tapply</a></span><span class="op">(</span><span class="va">Valeur</span>,<span class="va">Marque</span>,<span class="va">var</span><span class="op">)</span><span class="op">)</span>,<span class="fl">3</span><span class="op">)</span>
<span class="co">#&gt; Marque 1 Marque 2 Marque 3 </span>
<span class="co">#&gt;    0.756    1.105    0.882</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data<span class="op">=</span><span class="va">Marque.Valeur</span>,<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">Marque</span>,y<span class="op">=</span><span class="va">Valeur</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">""</span><span class="op">)</span></code></pre></div>
<p><img src="CodeChap09_files/figure-html/unnamed-chunk-13-1.png" width="700"></p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/options.html">options</a></span><span class="op">(</span>contrasts <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"contr.sum"</span>,<span class="st">"contr.sum"</span><span class="op">)</span><span class="op">)</span>
<span class="va">lm.Marque.Valeur</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Valeur</span><span class="op">~</span><span class="va">Marque</span>,data<span class="op">=</span><span class="va">Marque.Valeur</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">lm.Marque.Valeur</span><span class="op">)</span>
<span class="co">#&gt; Analysis of Variance Table</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Response: Valeur</span>
<span class="co">#&gt;           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    </span>
<span class="co">#&gt; Marque     2 110.676  55.338  60.502 &lt; 2.2e-16 ***</span>
<span class="co">#&gt; Residuals 87  79.575   0.915                      </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">lm.Marque.Valeur</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span>
<span class="co">#&gt; [1] 1.315667</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">res.model.MV</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">residuals</a></span><span class="op">(</span><span class="va">lm.Marque.Valeur</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test</a></span><span class="op">(</span><span class="va">res.model.MV</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Shapiro-Wilk normality test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  res.model.MV</span>
<span class="co">#&gt; W = 0.98958, p-value = 0.6999</span></code></pre></div>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/bartlett.test.html">bartlett.test</a></span><span class="op">(</span><span class="va">res.model.MV</span>,<span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Bartlett test of homogeneity of variances</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  res.model.MV and Marque.Valeur$Marque</span>
<span class="co">#&gt; Bartlett's K-squared = 1.0505, df = 2, p-value = 0.5914</span></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw">if</span><span class="op">(</span><span class="op">!</span><span class="op">(</span><span class="st">"ggiraphExtra"</span> <span class="op">%in%</span> <span class="fu"><a href="https://rdrr.io/r/utils/installed.packages.html">installed.packages</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"ggiraphExtra"</span><span class="op">)</span><span class="op">}</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/cardiomoon/ggiraphExtra">ggiraphExtra</a></span><span class="op">)</span>
<span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"M"</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">30</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">oav.Marque.Valeur</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/aov.html">aov</a></span><span class="op">(</span><span class="va">Valeur</span><span class="op">~</span><span class="va">Marque</span>,data<span class="op">=</span><span class="va">Marque.Valeur</span><span class="op">)</span>
<span class="va">resHSD</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TukeyHSD.html">TukeyHSD</a></span><span class="op">(</span><span class="va">oav.Marque.Valeur</span><span class="op">)</span>
<span class="va">resHSD</span>
<span class="co">#&gt;   Tukey multiple comparisons of means</span>
<span class="co">#&gt;     95% family-wise confidence level</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Fit: aov(formula = Valeur ~ Marque, data = Marque.Valeur)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $Marque</span>
<span class="co">#&gt;             diff       lwr      upr   p adj</span>
<span class="co">#&gt; M 2-M 1 1.478333 0.8895222 2.067144 1.0e-07</span>
<span class="co">#&gt; M 3-M 1 2.712667 2.1238555 3.301478 0.0e+00</span>
<span class="co">#&gt; M 3-M 2 1.234333 0.6455222 1.823144 8.8e-06</span></code></pre></div>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/pkg/ggiraphExtra/man/ggHSD.html">ggHSD</a></span><span class="op">(</span><span class="va">resHSD</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"Differences entre les niveaux moyens de Marque"</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"Intervalles de confiance globale 95%"</span><span class="op">)</span></code></pre></div>
<p><img src="CodeChap09_files/figure-html/unnamed-chunk-20-1.png" width="700"></p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">C1</span><span class="op">=</span><span class="fl">1</span><span class="op">+</span><span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">3</span><span class="op">*</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nlevels.html">nlevels</a></span><span class="op">(</span><span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">*</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">Marque.Valeur</span><span class="op">)</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/nlevels.html">nlevels</a></span><span class="op">(</span><span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">C1</span>
<span class="co">#&gt; [1] 1.015326</span></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fl">1</span><span class="op">/</span><span class="va">C1</span><span class="op">*</span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">Marque.Valeur</span><span class="op">)</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/nlevels.html">nlevels</a></span><span class="op">(</span><span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">)</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">oav.Marque.Valeur</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">`Mean Sq`</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">Marque.Valeur</span>,<span class="fu"><a href="https://rdrr.io/r/base/tapply.html">tapply</a></span><span class="op">(</span><span class="va">Valeur</span>,<span class="va">Marque</span>,<span class="va">var</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 1.050525</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/bartlett.test.html">bartlett.test</a></span><span class="op">(</span><span class="va">res.model.MV</span>,<span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Bartlett test of homogeneity of variances</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  res.model.MV and Marque.Valeur$Marque</span>
<span class="co">#&gt; Bartlett's K-squared = 1.0505, df = 2, p-value = 0.5914</span></code></pre></div>
</div>
<div id="qqplots" class="section level1">
<h1 class="hasAnchor">
<a href="#qqplots" class="anchor"></a>QQplots</h1>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># QQplot</span></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">oldpar</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span><span class="op">)</span>

<span class="va">Chemin</span> <span class="op">&lt;-</span> <span class="st">"~/Documents/Recherche/DeBoeck/Graphes/"</span>
<span class="va">colmodel</span><span class="op">=</span><span class="st">"cmyk"</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.stat.auckland.ac.nz/~yee/VGAM/">VGAM</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.1</span>, mgp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span>
<span class="va">ech_norm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="va">ech_norm</span>, ylab<span class="op">=</span><span class="st">""</span>,main<span class="op">=</span><span class="st">""</span>, xaxt<span class="op">=</span><span class="st">"n"</span>, yaxt<span class="op">=</span><span class="st">"n"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"bottomright"</span>,legend<span class="op">=</span><span class="st">"(a)"</span>,cex<span class="op">=</span><span class="fl">2</span>,bty<span class="op">=</span><span class="st">"n"</span><span class="op">)</span></code></pre></div>
<p><img src="CodeChap09_files/figure-html/unnamed-chunk-26-1.png" width="700"></p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.1</span>, mgp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span>
<span class="va">ech_laplace</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/VGAM/man/laplaceUC.html">rlaplace</a></span><span class="op">(</span><span class="fl">100</span>,<span class="fl">1</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="va">ech_laplace</span>, ylab<span class="op">=</span><span class="st">""</span>,main<span class="op">=</span><span class="st">""</span>, xaxt<span class="op">=</span><span class="st">"n"</span>, yaxt<span class="op">=</span><span class="st">"n"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"bottomright"</span>,legend<span class="op">=</span><span class="st">"(b)"</span>,cex<span class="op">=</span><span class="fl">2</span>,bty<span class="op">=</span><span class="st">"n"</span><span class="op">)</span></code></pre></div>
<p><img src="CodeChap09_files/figure-html/unnamed-chunk-28-1.png" width="700"></p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.1</span>, mgp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span>
<span class="va">ech_unif</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">100</span>,<span class="op">-</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="va">ech_unif</span>, ylab<span class="op">=</span><span class="st">"(c)"</span>,main<span class="op">=</span><span class="st">""</span>, xaxt<span class="op">=</span><span class="st">"n"</span>, yaxt<span class="op">=</span><span class="st">"n"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"bottomright"</span>,legend<span class="op">=</span><span class="st">"(c)"</span>,cex<span class="op">=</span><span class="fl">2</span>,bty<span class="op">=</span><span class="st">"n"</span><span class="op">)</span></code></pre></div>
<p><img src="CodeChap09_files/figure-html/unnamed-chunk-30-1.png" width="700"></p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.1</span>, mgp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span>
<span class="va">ech_exp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span><span class="fl">100</span>,<span class="fl">1</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="va">ech_exp</span>, ylab<span class="op">=</span><span class="st">""</span>,main<span class="op">=</span><span class="st">""</span>, xaxt<span class="op">=</span><span class="st">"n"</span>, yaxt<span class="op">=</span><span class="st">"n"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"bottomright"</span>,legend<span class="op">=</span><span class="st">"(d)"</span>,cex<span class="op">=</span><span class="fl">2</span>,bty<span class="op">=</span><span class="st">"n"</span><span class="op">)</span></code></pre></div>
<p><img src="CodeChap09_files/figure-html/unnamed-chunk-32-1.png" width="700"></p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.1</span>, mgp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span>
<span class="va">ech_mel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">50</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">50</span>,<span class="fl">5</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="va">ech_mel</span>, ylab<span class="op">=</span><span class="st">""</span>, main<span class="op">=</span><span class="st">""</span>, xaxt<span class="op">=</span><span class="st">"n"</span>, yaxt<span class="op">=</span><span class="st">"n"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"bottomright"</span>,legend<span class="op">=</span><span class="st">"(e)"</span>,cex<span class="op">=</span><span class="fl">2</span>,bty<span class="op">=</span><span class="st">"n"</span><span class="op">)</span></code></pre></div>
<p><img src="CodeChap09_files/figure-html/unnamed-chunk-34-1.png" width="700"></p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.1</span>, mgp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span>
<span class="va">ech_ext</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">99</span>,<span class="fl">0</span><span class="op">)</span>,<span class="fl">5</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="va">ech_ext</span>, ylab<span class="op">=</span><span class="st">""</span>,main<span class="op">=</span><span class="st">""</span>, xaxt<span class="op">=</span><span class="st">"n"</span>, yaxt<span class="op">=</span><span class="st">"n"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"bottomright"</span>,legend<span class="op">=</span><span class="st">"(f)"</span>,cex<span class="op">=</span><span class="fl">2</span>,bty<span class="op">=</span><span class="st">"n"</span><span class="op">)</span></code></pre></div>
<p><img src="CodeChap09_files/figure-html/unnamed-chunk-36-1.png" width="700"></p>
</div>
<div id="compléments--tests-non-paramétriques-pour-un-échantillon-" class="section level1">
<h1 class="hasAnchor">
<a href="#compl%C3%A9ments--tests-non-param%C3%A9triques-pour-un-%C3%A9chantillon-" class="anchor"></a>Compléments. Tests non-paramétriques pour un échantillon.</h1>
<div id="test-des-signes" class="section level2">
<h2 class="hasAnchor">
<a href="#test-des-signes" class="anchor"></a>Test des signes</h2>
<p>Soit un échantillon aléatoire <span class="math inline">\((X_1, X_2,\dots,X_n)\)</span> ayant pour loi parente une loi continue, caractérisée par la fonction de répartition <span class="math inline">\(F_X\)</span> dont la médiane est notée <span class="math inline">\(m_e\)</span> et la moyenne <span class="math inline">\(\mu\)</span>.</p>
<div id="hypothèses-testées" class="section level3">
<h3 class="hasAnchor">
<a href="#hypoth%C3%A8ses-test%C3%A9es" class="anchor"></a>Hypothèses testées</h3>
<p>Le test des signes permet de tester l’hypothèse suivante : <span class="math display">\[{\mathcal{H}}_{0}:\quad m_e=0\]</span> ou de façon équivalente <span class="math display">\[\mathbb{P}\left(X_i&gt;0\right)=1/2\]</span> contre <span class="math display">\[{\mathcal{H}}_{1}:\quad m_e\not=0\]</span> ou de façon équivalente <span class="math display">\[\mathbb{P}\left(X_i&gt;0\right)\not=1/2.\]</span></p>
<div id="remarques" class="section level4">
<h4 class="hasAnchor">
<a href="#remarques" class="anchor"></a>Remarques :</h4>
<ol style="list-style-type: decimal">
<li>Lorsque <span class="math inline">\(m_0\)</span> est un nombre réel, ce test permet de tester plus généralement l’hypothèse nulle <span class="math display">\[{{\mathcal{H}}_{0}}:{{m}_{e}}={{m}_{0}}\]</span> contre l’hypothèse alternative <span class="math display">\[{{\mathcal{H}}_{1}}:{{m}_{e}}\not{=}{{m}_{0}}.\]</span> Pour cela, il suffit de considérer l’échantillon aléatoire <span class="math inline">\((Y_1,\ldots,Y_n)\)</span> avec <span class="math inline">\(Y_i=X_i-m_0\)</span> et nous sommes ramenés au test précédent.</li>
<li>La formulation de ce test est bien sûr la formulation d’un test bilatéral. Nous pouvons envisager les deux tests unilatéraux correspondants qui s’écrivent : <span class="math display">\[{{\mathcal{H}}_{1}}\prime :\mathbb{P}\left( {{X}_{i}}&gt;0 \right)&lt;1/2\quad \textrm{ou} \quad {{\mathcal{H}}_{1}}\prime \prime :\mathbb{P}\left( {{X}_{i}}&gt;0 \right)&gt;1/2.\]</span> Dans le cas plus général d’une comparaison avec une norme <span class="math inline">\(m_0\)</span>, ils s’écrivent : <span class="math display">\[{{\mathcal{H}}_{1}}\prime :{{m}_{e}}&lt;{{m}_{0}} \quad\textrm{ou}\quad {{\mathcal{H}}_{1}}\prime \prime :{{m}_{e}}&gt;{{m}_{0}}.\]</span>
</li>
</ol>
</div>
</div>
<div id="absence-dobservations-nulles-parmi-les-données" class="section level3">
<h3 class="hasAnchor">
<a href="#absence-dobservations-nulles-parmi-les-donn%C3%A9es" class="anchor"></a>Absence d’observations nulles parmi les données</h3>
<div id="statistique-du-test" class="section level4">
<h4 class="hasAnchor">
<a href="#statistique-du-test" class="anchor"></a>Statistique du test</h4>
<p>La statistique <span class="math inline">\(S_n^+\)</span> du test des signes se définit par le nombre de variables aléatoires <span class="math inline">\(X_i\)</span>, <span class="math inline">\(1\leqslant i\leqslant n\)</span>, qui prennent une valeur positive ou encore : <span class="math display">\[S_n^+=\sum_{i=1}^n \mathbf{1}_{\{X_i&gt;0\}}.\]</span></p>
</div>
<div id="remarque" class="section level4">
<h4 class="hasAnchor">
<a href="#remarque" class="anchor"></a>Remarque :</h4>
<p>La loi de la statistique <span class="math inline">\(S_n^+\)</span> ne dépend pas de la loi continue <span class="math inline">\(F_X\)</span>. Propriétés : Lorsque l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> est vraie, la variable aléatoire <span class="math inline">\(S_n^+\)</span> a les trois propriétés suivantes : 1) <span class="math inline">\(S_n^+\)</span> suit la loi binomiale <span class="math inline">\(\mathcal{B}(n;p)\)</span> de paramètres <span class="math inline">\(n\)</span> et <span class="math inline">\(p=1/2\)</span>. Cette distribution binomiale est symétrique. 2) <span class="math inline">\(\mathbb{E}\left(S_n^+\right)=np=n/2\)</span> et <span class="math inline">\(\mathrm{Var}\left(S_n^+\right)=np(1-p)=n/4\)</span>. 3) Pour <span class="math inline">\(n\)</span> grand (<span class="math inline">\(n\geqslant 40\)</span>), nous utiliserons l’approximation normale avec correction de continuité : <span class="math display">\[\mathbb{P}_{\mathcal{H}_0}\left(S_n^+\leqslant k\right)=\mathbb{P}_{\mathcal{H}_0}\left(S_n^+\geqslant n-k\right)=\Phi\left(\frac{2k-n+1}{\sqrt n}\right)\]</span> où <span class="math inline">\(\Phi\)</span> est la fonction de répartition de la loi normale centrée-réduite <span class="math inline">\(\mathcal{N}(0;1)\)</span> et <span class="math inline">\(k\)</span> est un nombre entier compris entre 0 et <span class="math inline">\(n\)</span>.</p>
</div>
</div>
<div id="règle-de-décision-et-conclusion-du-test" class="section level3">
<h3 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test" class="anchor"></a>Règle de décision et conclusion du test</h3>
<ul>
<li>Premier cas : La taille <span class="math inline">\(n\)</span> est inférieure à <span class="math inline">\(40\)</span>. Pour un seuil donné <span class="math inline">\(\alpha\)</span>, nous cherchons, dans des tables de la loi binomiale <span class="math inline">\(\mathcal{B}(n;p)\)</span>, le plus grand nombre entier <span class="math inline">\(k_{\alpha}\)</span> tel que <span class="math inline">\(\mathbb{P}_{\mathcal{H}_0}\left(S_n^+\leqslant k_{\alpha}\right)\leqslant \alpha/2\)</span>. Alors nous décidons : <span class="math display">\[\left\{ \begin{align}
  &amp; \begin{matrix}
   si\ S_{n}^{+}(obs)\notin ]{{k}_{\alpha }};n-{{k}_{\alpha }}[ &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
\end{matrix} \\ 
 &amp; \begin{matrix}
   si\ S_{n}^{+}(obs)\in ]{{k}_{\alpha }};n-{{k}_{\alpha }}[ &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \\ 
\end{align} \right.\]</span>
</li>
<li>Second cas : La taille <span class="math inline">\(n\)</span> est supérieure ou égale à <span class="math inline">\(40\)</span>. La statistique <span class="math inline">\(S_n^+\)</span> suit approximativement la loi normale <span class="math inline">\(\mathcal{N}(n/2;\sqrt(n)/2)\)</span> et nous utilisons alors la statistique suivante qui tient compte de la correction de continuité : <span class="math display">\[Z_n=\frac{2S_n^+-n+1}{\sqrt{n}}\cdot\]</span> Pour un seuil donné <span class="math inline">\(\alpha\)</span>, une table de la loi normale centrée-réduite nous fournit une valeur critique <span class="math inline">\(c_{\alpha}\)</span> telle que <span class="math inline">\(\mathbb{P}_{\mathcal{H}_0}\left(-c_{\alpha}&lt;Z_n&lt;c_{\alpha}\right)=1-\alpha\)</span>. Alors nous décidons : <span class="math display">\[\left\{ \begin{align}
  &amp; \begin{matrix}
   si\ {{Z}_{n}}(obs)\notin ]-{{c}_{\alpha }};+{{c}_{\alpha }}[ &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
\end{matrix} \\ 
 &amp; \begin{matrix}
   si\ {{Z}_{n}}(obs)\in ]-{{c}_{\alpha }};+{{c}_{\alpha }}[ &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \\ 
\end{align} \right.\]</span>
</li>
</ul>
<div id="remarques-1" class="section level4">
<h4 class="hasAnchor">
<a href="#remarques-1" class="anchor"></a>Remarques :</h4>
<ol style="list-style-type: decimal">
<li>Dans le premier cas (<span class="math inline">\(n \leqslant 40\)</span>), le niveau de signification réel du test est égal à <span class="math inline">\(2\mathbb{P}_{\mathcal{H}_0}\left(S_n^+\leqslant k_{\alpha}\right)\)</span> qui est généralement strictement inférieur à <span class="math inline">\(\alpha\)</span>.</li>
<li>Dans le cas où il y a des ex quo dans les données, le protocole ne change pas.</li>
</ol>
</div>
</div>
<div id="présence-dobservations-nulles-parmi-les-données" class="section level3">
<h3 class="hasAnchor">
<a href="#pr%C3%A9sence-dobservations-nulles-parmi-les-donn%C3%A9es" class="anchor"></a>Présence d’observations nulles parmi les données</h3>
<p>Pour traiter ce problème, la méthode recommandée est la suivante : les éliminer et se ramener à un jeu de données de taille <span class="math inline">\(n\prime\)</span>, où <span class="math inline">\(n\prime\)</span> est le nombre d’observations non nulles, puis le traiter comme ci-dessus.</p>
</div>
</div>
<div id="test-des-rangs-signés-de-wilcoxon" class="section level2">
<h2 class="hasAnchor">
<a href="#test-des-rangs-sign%C3%A9s-de-wilcoxon" class="anchor"></a>Test des rangs signés de Wilcoxon</h2>
<p>Soit un échantillon aléatoire <span class="math inline">\((X_1, X_2,\dots,X_n)\)</span> ayant pour loi parente, une loi continue caractérisée par la fonction de répartition <span class="math inline">\(F_X\)</span> dont la médiane est notée <span class="math inline">\(m_e\)</span> et la moyenne <span class="math inline">\(\mu\)</span>.</p>
<div id="hypothèses-testées-1" class="section level3">
<h3 class="hasAnchor">
<a href="#hypoth%C3%A8ses-test%C3%A9es-1" class="anchor"></a>Hypothèses testées</h3>
<p>Le test des rangs signés de Wilcoxon permet de tester l’hypothèse suivante : <span class="math display">\[{{\mathcal{H}}_{0}}: \ \textrm{La loi continue $F_X$ est symétrique par rapport à l’origine}\]</span> contre <span class="math display">\[{{\mathcal{H}}_{1}}: \ \textrm{La loi continue $F_X$ n’est pas symétrique par rapport à l’origine.}\]</span> Ici l’origine c’est <span class="math inline">\(0\)</span>.</p>
<div id="remarques-2" class="section level4">
<h4 class="hasAnchor">
<a href="#remarques-2" class="anchor"></a>Remarques :</h4>
<ol style="list-style-type: decimal">
<li>Nous pouvons remplacer la valeur <span class="math inline">\(0\)</span> dans les hypothèses ci-dessus par une valeur fixée à l’avance, comme par exemple : 1, 2 ou <span class="math inline">\(\pi\)</span>.</li>
<li>Si nous savons que la loi continue <span class="math inline">\(F_X\)</span> est symétrique (pour le savoir, par exemple, tracer un histogramme), alors le test des rangs signés de Wilcoxon permet de tester l’hypothèse nulle suivante : <span class="math display">\[{\mathcal{H}}_{0}:\quad \mu=0\]</span> contre <span class="math display">\[{\mathcal{H}}_{1}:\quad \mu\not=0\]</span> ce qui permet de s’intéresser à la moyenne <span class="math inline">\(\mu\)</span> de la loi continue <span class="math inline">\(F_X\)</span>. Nous rappelons que, dans le cas d’une loi symétrique, la moyenne et la médiane sont confondues.</li>
<li>Nous introduisons l’échantillon <span class="math inline">\(Y_1,\ldots,Y_n\)</span>, avec <span class="math inline">\(Y_i=X_i-\mu_0\)</span>, pour tester l’hypothèse : <span class="math display">\[{\mathcal{H}}_{0}:\quad \mu=\mu_0\]</span> contre <span class="math display">\[{\mathcal{H}}_{1}:\quad \mu\not=\mu_0.\]</span>
</li>
<li>La formulation de ce test est la formulation d’un test bilatéral. Nous pourrions envisager d’étudier les deux tests unilatéraux correspondants.</li>
</ol>
</div>
</div>
<div id="absence-dex-quo-parmi-les-valeurs-absolues" class="section level3">
<h3 class="hasAnchor">
<a href="#absence-dex-quo-parmi-les-valeurs-absolues" class="anchor"></a>Absence d’ex quo parmi les valeurs absolues</h3>
<p>Soit <span class="math inline">\(\left(x_1,\ldots,x_n\right)\)</span> une réalisation de l’échantillon précédent.</p>
<p>À chaque <span class="math inline">\(x_i\)</span> nous attribuons le rang <span class="math inline">\(r_i^a\)</span> qui correspond au rang de <span class="math inline">\(|x_i|\)</span> lorsque les <span class="math inline">\(n\)</span> réalisations sont classées par ordre croissant de leurs valeurs absolues. Le rang <span class="math inline">\(r_i^a\)</span> est la réalisation d’une variable aléatoire <span class="math inline">\(R_i^a\)</span>.</p>
<div id="remarque-1" class="section level4">
<h4 class="hasAnchor">
<a href="#remarque-1" class="anchor"></a>Remarque :</h4>
<p>La lettre <span class="math inline">\(a\)</span> est là pour rappeler que nous travaillons sur les valeurs absolues des <span class="math inline">\(x_i\)</span>.</p>
</div>
</div>
<div id="statistique-du-test-1" class="section level3">
<h3 class="hasAnchor">
<a href="#statistique-du-test-1" class="anchor"></a>Statistique du test</h3>
<p>Nous déterminons alors la somme <span class="math inline">\(W_{n}^{+}(obs)\)</span> des rangs <span class="math inline">\(r_i^a\)</span> des seules observations strictement positives. La statistique <span class="math inline">\(W_n^{+}\)</span> du test des rangs signés de Wilcoxon est la variable aléatoire qui prend pour valeur la somme <span class="math inline">\(W_{n}^{+}(obs)\)</span>.</p>
<p>Par conséquent, la statistique <span class="math inline">\(W_n^{+}\)</span> du test des rangs signés de Wilcoxon de l’échantillon se définit par : <span class="math display">\[W_n^{+}=\sum_{\begin{array}{c}1\leqslant i \leqslant n
X_i&gt;0\end{array}}R_i^{a}.\]</span></p>
<div id="remarque-2" class="section level4">
<h4 class="hasAnchor">
<a href="#remarque-2" class="anchor"></a>Remarque :</h4>
<p>La loi de la statistique <span class="math inline">\(W_n^{+}\)</span> ne dépend pas de la loi continue <span class="math inline">\(F_X\)</span> des variables aléatoires <span class="math inline">\(X_i\)</span>.</p>
</div>
</div>
<div id="propriétés" class="section level3">
<h3 class="hasAnchor">
<a href="#propri%C3%A9t%C3%A9s" class="anchor"></a>Propriétés :</h3>
<p>Lorsque l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> est vraie, la variable aléatoire <span class="math inline">\(W_n^{+}\)</span> a les trois propriétés suivantes : 1) <span class="math inline">\(W_n^{+}\)</span> est symétrique autour de son espérance <span class="math inline">\(\mathbb{E}\left(W_n^{+}\right)=n(n+1)/4\)</span>. 2) <span class="math inline">\(\mathrm{Var}\left(W_n^{+}\right)=n(n+1)(2n+1)/24\)</span>. 3) <span class="math inline">\(W_n^{+}\)</span> est tabulée pour de faibles valeurs de <span class="math inline">\(n\)</span>. 4) Pour <span class="math inline">\(n\geqslant 15\)</span>, nous utiliserons l’approximation normale en tenant compte de la correction de continuité : <span class="math display">\[\displaystyle\mathbb{P}_{\mathcal{H}_0}\left(W_n^{+}\leqslant w\right)=\Phi\left(\frac{2w-\displaystyle\frac{n(n+1)}{2}+1}{\displaystyle\sqrt{\frac{n(n+1)(2n+1)}{6}}}\right)\]</span> où <span class="math inline">\(\Phi\)</span> est la fonction de répartition de la loi normale centrée-réduite <span class="math inline">\(\mathcal{N}(0;1)\)</span> et <span class="math inline">\(w\)</span> est un nombre entier compris entre 0 et <span class="math inline">\(n(n+1)/2\)</span>.</p>
</div>
<div id="règle-de-décision-et-conclusion-du-test-1" class="section level3">
<h3 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test-1" class="anchor"></a>Règle de décision et conclusion du test</h3>
<ul>
<li>Premier cas : La taille <span class="math inline">\(n\)</span> est inférieure à <span class="math inline">\(15\)</span>. Pour un seuil donné <span class="math inline">\(\alpha\)</span>, nous cherchons, dans les tables de la loi de Wilcoxon, le plus grand nombre entier <span class="math inline">\(w_{\alpha}\)</span> tel que <span class="math display">\[\mathbb{P}_{\mathcal{H}_0}\left(W_n^{+}\leqslant w_{\alpha}\right)\leqslant \alpha/2.\]</span> Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ W_{n}^{+}(obs)\notin ]{{w}_{\alpha }};n(n+1)/2-{{w}_{\alpha }}[ &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ W_{n}^{+}(obs)\in ]{{w}_{\alpha }};n(n+1)/2-{{w}_{\alpha }}[ &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span>
</li>
<li>Second cas : La taille <span class="math inline">\(n\)</span> est supérieure ou égale à <span class="math inline">\(15.\)</span> La statistique <span class="math inline">\(W_n^{+}\)</span> suit approximativement la loi normale <span class="math inline">\(\mathcal{N}(n(n+1)/4;\sqrt{n(n+1)(2n+1)/24})\)</span> et nous utilisons alors la statistique suivante qui tient compte de la correction de continuité : <span class="math display">\[Z_{n}=\frac{2W_n^{+}-\displaystyle\frac{n(n+1)}{2}+1}{\sqrt{\displaystyle\frac{n(n+1)(2n+1)}{6}}}\cdot\]</span> Pour un seuil donné <span class="math inline">\(\alpha\)</span>, une table de la loi normale centrée-réduite nous fournit une valeur critique <span class="math inline">\(c_{\alpha}\)</span> telle que <span class="math inline">\(\mathbb{P}_{\mathcal{H}_0}\left(-c_{\alpha}&lt;Z_n&lt;c_{\alpha}\right)= 1-\alpha\)</span>. Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ {{Z}_{n}}(obs)\not{\in }]-{{c}_{\alpha }};+{{c}_{\alpha }}[ &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ {{Z}_{n}}(obs)\in ]-{{c}_{\alpha }};+{{c}_{\alpha }}[ &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span>
</li>
</ul>
<div id="remarques-3" class="section level4">
<h4 class="hasAnchor">
<a href="#remarques-3" class="anchor"></a>Remarques :</h4>
<ol style="list-style-type: decimal">
<li>Dans le premier cas, lorsque nous rejetons <span class="math inline">\(\mathcal{H}_0\)</span>, nous décidons que <span class="math inline">\(\mathcal{H}_1\)</span> est vraie avec un risque d’erreur de première espèce au plus égal à <span class="math inline">\(\alpha\)</span>. En effet, le niveau de signification réel du test est égal à <span class="math inline">\(2\mathbb{P}_{\mathcal{H}_0}\left(W_n^{+}\leqslant w_{\alpha}\right)\)</span> qui est généralement strictement inférieur à <span class="math inline">\(\alpha\)</span>.</li>
<li>Lorsque nous conservons <span class="math inline">\(\mathcal{H}_0\)</span>, c’est avec un risque d’erreur de deuxième espèce <span class="math inline">\(\beta\)</span> qui est difficile à évaluer.</li>
</ol>
</div>
</div>
<div id="présence-dex-quo-parmi-les-valeurs-absolues-méthode-des-rangs-moyens" class="section level3">
<h3 class="hasAnchor">
<a href="#pr%C3%A9sence-dex-quo-parmi-les-valeurs-absolues-m%C3%A9thode-des-rangs-moyens" class="anchor"></a>Présence d’ex quo parmi les valeurs absolues : Méthode des rangs moyens</h3>
<p>Cette méthode est la plus utilisée, en particulier dans la plupart des logiciels statistiques.</p>
<p>Les observations <span class="math inline">\(x_1,\ldots,x_n\)</span> peuvent présenter des ex quo et a fortiori leurs valeurs absolues.</p>
<div id="statistique-du-test-2" class="section level4">
<h4 class="hasAnchor">
<a href="#statistique-du-test-2" class="anchor"></a>Statistique du test</h4>
<p>En associant à la variable <span class="math inline">\(X_i\)</span> son rang moyen <span class="math inline">\(R_i^{a{\star}}\)</span> dans le classement des valeurs absolues et en sommant tous les rangs pour lesquels <span class="math inline">\(X_i&gt;0\)</span> nous obtenons la statistique : <span class="math display">\[W_n^{+\star}=\sum_{\begin{array}{c}1\leqslant i \leqslant n\\ X_i&gt;0\end{array}}R_i^{a{\star}}.\]</span></p>
</div>
<div id="remarque-3" class="section level4">
<h4 class="hasAnchor">
<a href="#remarque-3" class="anchor"></a>Remarque :</h4>
<p>Le symbole <span class="math inline">\(\star\)</span> est là pour rappeler que nous sommes dans le cas où il y a des ex quo. Les valeurs absolues observées <span class="math inline">\(|x_1|,\ldots,|x_n|\)</span> sont ordonnées puis regroupées en classes d’ex quo, <span class="math inline">\(C_0\)</span> pour la première classe qui est constituée des nombres <span class="math inline">\(|x_i|\)</span> nuls, s’il en existe, et <span class="math inline">\(C_j\)</span>, <span class="math inline">\(1\leqslant j \leqslant h\)</span> pour les autres nombres.</p>
<p>Certaines classes <span class="math inline">\(C_j\)</span> peuvent comporter un seul élément, si cet élément n’a pas d’ex quo. Notons <span class="math inline">\(d_j\)</span> le nombre d’ex quo de la classe <span class="math inline">\(C_j\)</span>. Nous avons : <span class="math display">\[d_0+\displaystyle{\sum_{j=1}^h}d_j=n.\]</span></p>
</div>
<div id="propriétés-1" class="section level4">
<h4 class="hasAnchor">
<a href="#propri%C3%A9t%C3%A9s-1" class="anchor"></a>Propriétés :</h4>
<p>Lorsque l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> est vraie, la variable aléatoire <span class="math inline">\(W_n^{+\star}\)</span> a les trois propriétés suivantes : 1) <span class="math inline">\(\mathbb{E}(W_{n}^{+\star })={{m}^{\star }}=\frac{n(n+1)-{{d}_{0}}({{d}_{0}}+1)}{4}\)</span> 2) <span class="math display">\[\text{Var}(W_{n}^{+\star })={{\left( {{\sigma }^{\star }} \right)}^{2}}=\frac{n(n+1)(2n+1)-{{d}_{0}}({{d}_{0}}+1)(2{{d}_{0}}+1)}{24}-\frac{\sum\limits_{j=1}^{h}{\left( d_{j}^{3}-{{d}_{j}} \right)}}{48}\cdot\]</span> 3) Pour <span class="math inline">\(n&gt;15\)</span>, nous admettrons que la variable aléatoire <span class="math inline">\(\frac{W_n^{+\star}-m^{\star}}{\sigma^{\star}}\)</span> suit approximativement la loi normale centrée-réduite <span class="math inline">\(\mathcal{N}(0\,;1)\)</span> où <span class="math inline">\(m^{\star}\)</span> et <span class="math inline">\(\sigma^{\star}\)</span> ont été définis ci-dessus.</p>
</div>
</div>
<div id="règle-de-décision-et-conclusion-du-test-2" class="section level3">
<h3 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test-2" class="anchor"></a>Règle de décision et conclusion du test</h3>
<p>Premier cas : L’effectif de l’échantillon <span class="math inline">\(n\)</span> est inférieur à <span class="math inline">\(15.\)</span> Pour ces valeurs de <span class="math inline">\(n\)</span>, les calculs « à la main » sont fastidieux. Mais il existe des logiciels qui traitent parfaitement ce cas. Nous conclurons grâce à la <span class="math inline">\(p\)</span>-valeur qui sera calculée.</p>
<p>Second cas : Même règle et même conclusion que dans le cas où il n’y a pas d’ex quo en remplaçant <span class="math inline">\(W_n^+\)</span> par <span class="math inline">\(W_n^{+\star}\)</span>.</p>
<div id="remarques-4" class="section level4">
<h4 class="hasAnchor">
<a href="#remarques-4" class="anchor"></a>Remarques :</h4>
<ol style="list-style-type: decimal">
<li>Lorsque nous utilisons cette méthode des rangs moyens, nous ne pouvons pas utiliser les tables statistiques usuelles qui concernent la distribution de la statistique <span class="math inline">\(W_n^{+}\)</span>.</li>
<li>Par extension nous pourrons utiliser la procédure ci-dessus lorsque la loi <span class="math inline">\(F_X\)</span> des variables aléatoires <span class="math inline">\(X_i\)</span> est discrète.</li>
</ol>
</div>
</div>
</div>
<div id="test-de-mann-whitney" class="section level2">
<h2 class="hasAnchor">
<a href="#test-de-mann-whitney" class="anchor"></a>Test de Mann-Whitney</h2>
<p>Le test de Mann-Whitney a été introduit en 1947 indépendamment du test de la somme des rangs de Wilcoxon qui a été élaboré en 1945. Ces deux tests, d’une formulation différente, sont en fait équivalents. En fonction de l’outil informatique utilisé, la dénomination du test pourra être l’une des suivantes : Test de Mann-Whitney, Test de la somme des rangs de Wilcoxon ou encore Test de Wilcoxon-Mann-Whitney. L’approche de Mann et Whitney paraît souvent plus facile à mettre en pratique.</p>
<p>Si nous devons utiliser une table, il nous faudra déterminer quelle a été l’approche utilisée par le logiciel statistique et nous servir de l’une des tables appropriées.</p>
<p>Nous observons, de manière indépendante, une variable aléatoire <span class="math inline">\(X\)</span> de loi continue sur deux populations ou sur une population divisée en deux sous-populations.</p>
<p>Nous obtenons ainsi deux séries d’observations notées <span class="math inline">\((x_{1,1},\ldots,x_{1,n_1})\)</span> pour la première et <span class="math inline">\((x_{2,1},\ldots,x_{2,n_2})\)</span> pour la seconde.</p>
<p>Nous notons <span class="math inline">\(\mathcal{L}_i(X)\)</span> la loi de la variable aléatoire <span class="math inline">\(X\)</span> sur la <span class="math inline">\(i\)</span>-eme (sous-)population.</p>
<p>Sans faire d’hypothèses spécifiques, le test de Mann-Whitney-Wilcoxon ne permet pas de tester l’égalité des moyennes ni celle des médianes entre les deux (sous-)populations même dans le cas où les variances ou les mads (median of absolute differences to the median, voir la Section correspondante de la variable <span class="math inline">\(X\)</span> sont égales sur les deux (sous-)populations. Pour s’en convaincre, il suffit de s’intéresser à l’exemple suivant :</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">Premier_echantillon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span>,<span class="fl">3</span>,<span class="fl">4</span>,<span class="fl">5</span>,<span class="fl">6</span>,<span class="fl">7</span>,<span class="fl">8</span>,<span class="fl">9</span>,<span class="fl">20</span>,<span class="fl">21</span>,<span class="fl">22</span>,<span class="fl">23</span>,<span class="fl">24</span>,<span class="fl">25</span>,<span class="fl">26</span>,<span class="fl">27</span>,<span class="fl">28</span>,<span class="fl">29</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">Premier_echantillon</span><span class="op">)</span>
<span class="co">#&gt; [1] 10.39146</span>
<span class="fu"><a href="https://rdrr.io/r/stats/mad.html">mad</a></span><span class="op">(</span><span class="va">Premier_echantillon</span>,constant <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="co">#&gt; [1] 9</span>
<span class="va">Second_echantillon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span>,<span class="fl">11</span>,<span class="fl">12</span>,<span class="fl">13</span>,<span class="fl">14</span>,<span class="fl">15</span>,<span class="fl">16</span>,<span class="fl">17</span>,<span class="fl">18</span>,<span class="fl">19</span>,<span class="fl">30</span>,<span class="fl">31</span>,<span class="fl">32</span>,<span class="fl">33</span>,<span class="fl">34</span>,<span class="fl">35</span>,<span class="fl">36</span>,<span class="fl">37</span>,<span class="fl">38</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">Second_echantillon</span><span class="op">)</span>
<span class="co">#&gt; [1] 10.39146</span>
<span class="fu"><a href="https://rdrr.io/r/stats/mad.html">mad</a></span><span class="op">(</span><span class="va">Second_echantillon</span>,constant <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="co">#&gt; [1] 9</span></code></pre></div>
<div id="hypothèses-testées-2" class="section level3">
<h3 class="hasAnchor">
<a href="#hypoth%C3%A8ses-test%C3%A9es-2" class="anchor"></a>Hypothèses testées</h3>
<p>Le test de Mann-Whitney permet de tester l’hypothèse suivante : <span class="math display">\[{\mathcal{H}}_{0}:\quad \mathcal{L}_1(X)=\mathcal{L}_2(X)\]</span> contre <span class="math display">\[{\mathcal{H}}_{1}:\quad \mathcal{L}_1(X)\not=\mathcal{L}_2(X).\]</span></p>
</div>
<div id="absence-dex-quo-parmi-les-observations" class="section level3">
<h3 class="hasAnchor">
<a href="#absence-dex-quo-parmi-les-observations" class="anchor"></a>Absence d’ex quo parmi les observations</h3>
<div id="statistique-du-test-3" class="section level4">
<h4 class="hasAnchor">
<a href="#statistique-du-test-3" class="anchor"></a>Statistique du test</h4>
<p>Pour obtenir la statistique <span class="math inline">\(U_{n_1,n_2}\)</span> du test de Mann-Whitney, en général, nous devons procéder à des calculs successifs : 1. Nous classons par ordre croissant l’ensemble des observations des deux échantillons <span class="math inline">\((x_{1,1},\ldots,x_{1,n_1})\)</span> et <span class="math inline">\((x_{2,1},\ldots,x_{2,n_1})\)</span> de taille respective <span class="math inline">\(n_1\)</span> et <span class="math inline">\(n_2\)</span>. 2. Nous affectons le rang correspondant. 3. Nous effectuons les sommes des rangs pour chacun des deux échantillons, notées <span class="math inline">\(R_{n_1}\)</span> et <span class="math inline">\({{R}_{{{n}_{2}}}}.\)</span> 4. Nous en déduisons les quantités <span class="math inline">\(U_{n_1}\)</span> et <span class="math inline">\(U_{n_2}\)</span> qui se calculent ainsi : <span class="math display">\[U_{n_1}=n_1 n_2 +\frac{n_1(n_1+1)}{2}-R_{n_1}
\quad\mbox{et}\quad
U_{n_2}=n_1 n_2 +\frac{n_2(n_2+1)}{2}-R_{n_2}=n_1 n_2-U_{n_1}.\]</span> Enfin, la statistique <span class="math inline">\(U_{n_1,n_2}\)</span> du test de Mann-Whitney se définit comme étant la plus petite des deux valeurs <span class="math inline">\(U_{n_1}\)</span> et <span class="math inline">\(U_{n_2}\)</span>.</p>
</div>
<div id="propriétés-2" class="section level4">
<h4 class="hasAnchor">
<a href="#propri%C3%A9t%C3%A9s-2" class="anchor"></a>Propriétés :</h4>
<p>Lorsque l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> est vraie, la variable aléatoire <span class="math inline">\(U_{n_1,n_2}\)</span> a les trois propriétés suivantes : 1. <span class="math inline">\(U_{n_1,n_2}\)</span> est symétrique autour de son espérance <span class="math inline">\(\mathbb{E}\left(U_{n_1,n_2}\right)=n_1n_2/2\)</span>. 2. <span class="math inline">\(\mathrm{Var}\left(U_{n_1,n_2}\right)=n_1n_2(n_1+n_2+1)/12\)</span>. 3. <span class="math inline">\(U_{n_1,n_2}\)</span> est tabulée pour de faibles valeurs de <span class="math inline">\(n_1\)</span> et de <span class="math inline">\(n_2\)</span>. 4. Pour <span class="math inline">\(n_1&gt; 20\)</span> et <span class="math inline">\(n_2&gt; 20\)</span>, nous utiliserons l’approximation normale avec correction de continuité : <span class="math display">\[\displaystyle\mathbb{P}_{\mathcal{H}_0}\left(U_{n_1,n_2}\leqslant u\right)=\Phi\left(\frac{2u+1-n_1n_2}{\sqrt{\displaystyle\frac{n_1n_2(n_1+n_2+1)}{3}}}\right)\]</span> où <span class="math inline">\(\Phi\)</span> est la fonction de répartition de la loi normale centrée-réduite et <span class="math inline">\(u\)</span> est un nombre entier.</p>
</div>
<div id="remarque-4" class="section level4">
<h4 class="hasAnchor">
<a href="#remarque-4" class="anchor"></a>Remarque :</h4>
<p>La statistique de Wilcoxon, notée <span class="math inline">\(W_{n_1,n_2}\)</span>, est égale à la somme des rangs pour le premier échantillon : <span class="math inline">\(W_{n_1,n_2}=R_{n_1}\)</span>. Nous avons les égalités suivantes : <span class="math inline">\(\mathbb{E}\left(W_{n_1,n_2}\right)=n_1\left(n_1+n_2+1\right)/2\)</span> et <span class="math inline">\(\mathrm{Var}\left(W_{n_1,n_2}\right)=n_1n_2(n_1+n_2+1)/12\)</span>.</p>
</div>
<div id="règle-de-décision-et-conclusion-du-test-3" class="section level4">
<h4 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test-3" class="anchor"></a>Règle de décision et conclusion du test</h4>
<ol style="list-style-type: decimal">
<li>Premier cas : Les tailles <span class="math inline">\(n_1\)</span> ou <span class="math inline">\(n_2\)</span> sont inférieures ou égales à <span class="math inline">\(20.\)</span> Pour un seuil donné <span class="math inline">\(\alpha\)</span>, des tables de la loi de Mann-Whitney nous fournissent une valeur critique <span class="math inline">\(c_{\alpha}\)</span>. Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ {{U}_{{{n}_{1}},{{n}_{2}}}}(obs){{c}_{\alpha }} &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ {{U}_{{{n}_{1}},{{n}_{2}}}}(obs)&gt;{{c}_{\alpha }} &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span> Le niveau de signification réel du test est généralement strictement inférieur à <span class="math inline">\(\alpha\)</span>.</li>
<li>Second cas : Les tailles <span class="math inline">\(n_1\)</span> et <span class="math inline">\(n_2\)</span> sont supérieures strictement à <span class="math inline">\(20.\)</span> La statistique <span class="math inline">\(U_{n_1,n_2}\)</span> suit approximativement la loi normale <span class="math inline">\(\mathcal{N}(n_1n_2/2;\sqrt{n_1n_2(n_1+n_2+1)/12})\)</span> et nous utilisons alors la statistique suivante qui tient compte de la correction de continuité : <span class="math display">\[Z_{n_1,n_2}=\frac{2U_{n_1,n_2}+1-n_1n_2}{\sqrt{\displaystyle\frac{n_1n_2(n_1+n_2+1)}{3}}}\cdot\]</span> Pour un seuil donné <span class="math inline">\(\alpha\)</span>, une table de la loi normale centrée-réduite nous fournit une valeur critique <span class="math inline">\(c_{\alpha}\)</span> telle que <span class="math inline">\(\mathbb{P}_{\mathcal{H}_0}\left(-c_{\alpha} &lt; Z_{n_1,n_2} &lt; c_{\alpha}\right)=1-\alpha\)</span>. Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ {{Z}_{{{n}_{1}},{{n}_{2}}}}(obs)\notin ]-{{c}_{\alpha }};+{{c}_{\alpha }}[ &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ {{Z}_{{{n}_{1}},{{n}_{2}}}}(obs)\in ]-{{c}_{\alpha }};+{{c}_{\alpha }}[ &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span>
</li>
</ol>
<p>Lorsque nous rejetons <span class="math inline">\(\mathcal{H}_0\)</span>, nous décidons que <span class="math inline">\(\mathcal{H}_1\)</span> est vraie avec un risque d’erreur de première espèce <span class="math inline">\(\alpha\)</span>.</p>
<p>Lorsque nous conservons <span class="math inline">\(\mathcal{H}_0\)</span>, c’est avec un risque d’erreur de deuxième espèce <span class="math inline">\(\beta\)</span>.</p>
</div>
</div>
<div id="présence-dex-quo-parmi-les-observations-méthode-des-rangs-moyens" class="section level3">
<h3 class="hasAnchor">
<a href="#pr%C3%A9sence-dex-quo-parmi-les-observations-m%C3%A9thode-des-rangs-moyens" class="anchor"></a>Présence d’ex quo parmi les observations : Méthode des rangs moyens</h3>
<p>Cette méthode est la plus utilisée, en particulier dans la plupart des logiciels statistiques.</p>
<div id="modification-de-la-statistique-du-test" class="section level4">
<h4 class="hasAnchor">
<a href="#modification-de-la-statistique-du-test" class="anchor"></a>Modification de la statistique du test</h4>
<p>Les observations <span class="math inline">\(x_1\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(x_{n_1}\)</span>, <span class="math inline">\(y_1\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(y_{n_2}\)</span> peuvent présenter des ex quo. Les valeurs observées <span class="math inline">\(x_1\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(x_{n_1}\)</span>, <span class="math inline">\(y_1\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(y_{n_2}\)</span> sont ordonnées puis regroupées en <span class="math inline">\(h\)</span> classes d’ex quo <span class="math inline">\(C_j\)</span>, <span class="math inline">\(1\leqslant j \leqslant h\)</span>.</p>
<p>Certaines classes <span class="math inline">\(C_j\)</span> peuvent comporter un seul élément, si cet élément n’a pas d’ex quo. Notons <span class="math inline">\(d_j\)</span> le nombre d’ex quo de la classe <span class="math inline">\(C_j\)</span>. Nous avons : <span class="math display">\[\displaystyle{\sum_{j=1}^h}d_j=n_1+n_2.\]</span> En associant à la variable <span class="math inline">\(X_i\)</span> son rang moyen <span class="math inline">\(R_i^{\star}\)</span> dans ce classement et en sommant les rangs de tous les éléments <span class="math inline">\(X_i\)</span> du premier échantillon, nous obtenons la statistique de Wilcoxon modifiée pour prendre en compte la présence d’ex quo, <span class="math inline">\(W_{n_1,n_2}^{\star}\)</span> : <span class="math display">\[W_{n_1,n_2}^{\star}=\sum_{i=1}^{n_1}R_i^{\star}.\]</span></p>
</div>
<div id="propriétés-3" class="section level4">
<h4 class="hasAnchor">
<a href="#propri%C3%A9t%C3%A9s-3" class="anchor"></a>Propriétés :</h4>
<p>Lorsque l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> est vraie, la variable aléatoire <span class="math inline">\(W_{n_1,n_2}^{\star}\)</span> a les trois propriétés suivantes : 1. <span class="math inline">\(\mathbb{E}\left(W_{n_1,n_2}^{\star}\right)=m^{\star}=n_1\left(n_1+n_2+1\right)/2\)</span>. 2. <span class="math display">\[\text{Var}\left( W_{{{n}_{1}},{{n}_{2}}}^{\star } \right)={{\left( {{\sigma }^{\star }} \right)}^{2}}=\frac{{{n}_{1}}{{n}_{2}}\left( {{n}_{1}}+{{n}_{2}}+1 \right)}{12}-\frac{\frac{{{n}_{1}}{{n}_{2}}}{({{n}_{1}}+{{n}_{2}})({{n}_{1}}+{{n}_{2}}-1)}\sum\limits_{j=1}^{h}{\left( d_{j}^{3}-{{d}_{j}} \right)}}{12}\cdot \]</span> 3. Pour <span class="math inline">\(n_1&gt;15\)</span> et <span class="math inline">\(n_2&gt;15\)</span>, nous utiliserons l’approximation normale avec correction de continuité : <span class="math display">\[\displaystyle\mathbb{P}_{\mathcal{H}_0}\left(W_{n_1,n_2}^{\star}\leqslant u\right)=\Phi\left(\frac{u-m^{\star}+1/2}{\sigma^{\star}}\right)\]</span> où <span class="math inline">\(\Phi\)</span> est la fonction de répartition de la loi normale centrée-réduite et <span class="math inline">\(u\)</span> est un nombre entier.</p>
</div>
<div id="remarques-5" class="section level4">
<h4 class="hasAnchor">
<a href="#remarques-5" class="anchor"></a>Remarques :</h4>
<ol style="list-style-type: decimal">
<li>Lorsque nous utilisons cette méthode des rangs moyens, nous ne pouvons pas utiliser les tables statistiques usuelles qui concernent la distribution de la variable aléatoire <span class="math inline">\(W_{n_1,n_2}\)</span>, ni celle de <span class="math inline">\(U_{n_1,n_2}\)</span>.</li>
<li>Par extension nous pourrons utiliser cette procédure lorsque les lois <span class="math inline">\(\mathcal{L}_1\)</span> et <span class="math inline">\(\mathcal{L}_2\)</span> des variables aléatoires <span class="math inline">\(X_i\)</span> sont discrètes.</li>
</ol>
</div>
<div id="règle-de-décision-et-conclusion-du-test-4" class="section level4">
<h4 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test-4" class="anchor"></a>Règle de décision et conclusion du test</h4>
<ul>
<li>Premier cas : Les tailles <span class="math inline">\(n_1\)</span> ou <span class="math inline">\(n_2\)</span> sont inférieures ou égales à <span class="math inline">\(15.\)</span> Pour ces valeurs, les calculs « à la main » sont fastidieux. Il est conseillé d’avoir recours à un logiciel qui sait traiter ce cas. Nous conclurons grâce à la <span class="math inline">\(p\)</span>-valeur qu’il calculera.</li>
<li>Second cas : Les tailles <span class="math inline">\(n_1\)</span> et <span class="math inline">\(n_2\)</span> sont supérieures strictement à <span class="math inline">\(15.\)</span> La statistique <span class="math inline">\(W_{n_1,n_2}^{\star}\)</span> suit approximativement la loi normale <span class="math inline">\(\mathcal{N}(m^{\star};\sigma^{\star})\)</span> et nous utilisons alors la statistique suivante qui tient compte de la correction de continuité : <span class="math display">\[Z_{n_1,n_2}^{\star}=\frac{W_{n_1,n_2}^{\star}-m^{\star}+1/2}{\sigma^{\star}}\cdot\]</span> Pour un seuil donné <span class="math inline">\(\alpha\)</span>, une table de la loi normale centrée réduite nous fournit une valeur critique <span class="math inline">\(c_\alpha\)</span> telle que <span class="math inline">\(\mathbb{P}_{\mathcal{H}_0}\left(-c_{\alpha} &lt; Z_{n_1,n_2}^{\star}&lt; c_{\alpha}\right)=1-\alpha\)</span>. Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ Z_{{{n}_{1}},{{n}_{2}}}^{\star }(obs)\notin ]-{{c}_{\alpha }};+{{c}_{\alpha }}[ &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ Z_{{{n}_{1}},{{n}_{2}}}^{\star }(obs)\in ]-{{c}_{\alpha }};+{{c}_{\alpha }}[ &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span> Remarque pour les deux cas :</li>
<li>Lorsque nous rejetons <span class="math inline">\(\mathcal{H}_0\)</span>, nous décidons que <span class="math inline">\(\mathcal{H}_1\)</span> est vraie avec un risque d’erreur de première espèce <span class="math inline">\(\alpha\)</span>.</li>
<li>Lorsque nous conservons <span class="math inline">\(\mathcal{H}_0\)</span>, c’est avec un risque d’erreur de deuxième espèce <span class="math inline">\(\beta\)</span>.</li>
</ul>
</div>
</div>
</div>
<div id="test-de-la-médiane-de-mood" class="section level2">
<h2 class="hasAnchor">
<a href="#test-de-la-m%C3%A9diane-de-mood" class="anchor"></a>Test de la médiane de Mood</h2>
<p>Nous considérons deux échantillons aléatoires indépendants <span class="math inline">\((X_1,\ldots,X_{n_1})\)</span> et <span class="math inline">\((Y_1,\ldots,Y_{n_2})\)</span>. <span class="math inline">\((X_1,\ldots,X_{n_1})\)</span> est distribué suivant une loi continue <span class="math inline">\(\mathcal{L}_X\)</span> de fonction de répartition <span class="math inline">\(F_X\)</span> et <span class="math inline">\((Y_1,\ldots,Y_{n_2})\)</span> suivant une loi continue <span class="math inline">\(\mathcal{L}_Y\)</span> de fonction de répartition <span class="math inline">\(G_Y\)</span>.</p>
<div id="hypothèses-testées-3" class="section level3">
<h3 class="hasAnchor">
<a href="#hypoth%C3%A8ses-test%C3%A9es-3" class="anchor"></a>Hypothèses testées</h3>
<p>Le test de la médiane de Mood permet de tester l’hypothèse suivante : <span class="math display">\[{\mathcal{H}}_{0}:\quad \textrm{Les deux lois continues} \  \mathcal{L}_X\ \textrm{et} \ \mathcal{L}_Y \ \textrm{sont égales}\]</span> contre <span class="math display">\[{\mathcal{H}}_{0}:\quad \textrm{Les deux lois continues} \  \mathcal{L}_X\ \textrm{et} \ \mathcal{L}_Y \ \textrm{ne sont pas égales}\]</span></p>
<p>Cette hypothèse peut également se résumer ainsi : <span class="math display">\[{\mathcal{H}}_{0}:\quad F_X=G_Y\]</span> contre <span class="math display">\[{\mathcal{H}}_{1}:\quad F_X\neq G_Y.\]</span></p>
<div id="remarque-5" class="section level4">
<h4 class="hasAnchor">
<a href="#remarque-5" class="anchor"></a>Remarque :</h4>
<p>Ce test permet également de réaliser des tests unilatéraux.</p>
</div>
</div>
<div id="procédure-du-test" class="section level3">
<h3 class="hasAnchor">
<a href="#proc%C3%A9dure-du-test" class="anchor"></a>Procédure du test</h3>
<div id="statistique-du-test-4" class="section level4">
<h4 class="hasAnchor">
<a href="#statistique-du-test-4" class="anchor"></a>Statistique du test</h4>
<p>Après regroupement des <span class="math inline">\(n_1+n_2\)</span> valeurs des deux échantillons, <span class="math inline">\(n_1 \times M_{N}\)</span> est le nombre d’observations <span class="math inline">\(X_i\)</span> qui sont supérieures à la médiane des <span class="math inline">\(N=n_1+n_2\)</span> observations.</p>
</div>
<div id="propriétés-4" class="section level4">
<h4 class="hasAnchor">
<a href="#propri%C3%A9t%C3%A9s-4" class="anchor"></a>Propriétés :</h4>
<p>Lorsque l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> est vraie, la variable aléatoire <span class="math inline">\(n_1 \times M_{N}\)</span> a les cinq propriétés suivantes : 1. La variable aléatoire <span class="math inline">\(n_1 \times M_{N}\)</span> peut prendre les valeurs <span class="math inline">\(0\)</span>, <span class="math inline">\(1\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(n_1\)</span> selon la distribution hypergéométrique suivante : <span class="math display">\[\mathbb{P}_{\mathcal{H}_0}\left(n_1\times M_N = k\right)=\frac{C_{n_1}^k C_{n_2}^{N/2-k}}{C_{N}^{N/2}}\cdot\]</span> 2. <span class="math inline">\(\displaystyle\mathbb{E}\left(n_1\times M_N\right)=\frac{n_1(n_1+n_2-\epsilon_{N})}{2N}\cdot\)</span> 3. <span class="math inline">\(\displaystyle\mathrm{Var}\left(n_1\times M_N\right)=\frac{n_1 n_2 (n_1+n_2+1)}{4(n_1+n_2-1+\epsilon_N)(n_1+n_2+1-\epsilon_N)}\)</span> où <span class="math inline">\(\epsilon_N=0\)</span> si <span class="math inline">\(N\)</span> est pair et <span class="math inline">\(\epsilon_{N}=1\)</span> si <span class="math inline">\(N\)</span> est impair. 4. Lorsque les tailles <span class="math inline">\(n_1\)</span> et <span class="math inline">\(n_2\)</span> sont grandes, c’est-à-dire <span class="math inline">\(n_1 \geqslant 25\)</span> et <span class="math inline">\(n_2 \geqslant 25\)</span>, nous utiliserons l’approximation normale avec correction de continuité : <span class="math display">\[\displaystyle\mathbb{P}_{\mathcal{H}_0}\left(n_1\times M_N\leqslant m\right)=\Phi\left(\frac{n_1\times m-\mathbb{E}\left(n_1\times M_N\right)+1/2}{\sqrt{\mathrm{Var}\left(n_1\times M_N\right)}}\right)\]</span> où <span class="math inline">\(\Phi\)</span> est la fonction de répartition de la loi normale centrée-réduite et <span class="math inline">\(u\)</span> est un nombre entier. 5. La distribution est symétrique lorsque <span class="math inline">\(N\)</span> est pair. Règle de décision et conclusion du test * Premier cas : Les tailles <span class="math inline">\(n_1\)</span> et <span class="math inline">\(n_2\)</span> sont petites, c’est-à-dire <span class="math inline">\(n_1 \leqslant 25\)</span> et <span class="math inline">\(n_2 \leqslant 25\)</span>. Pour un seuil donné <span class="math inline">\(\alpha\)</span>, nous cherchons, dans les tables de la loi hypergéométrique, le plus grand entier <span class="math inline">\(k_{\alpha}\)</span> tel que <span class="math inline">\(\mathbb{P}_{\mathcal{H}_0}\left(n_1\times M_N \leqslant k_{\alpha}\right) &lt; \alpha/2\)</span> et le plus grand entier <span class="math inline">\(k\prime _{\alpha}\)</span> tel que <span class="math inline">\(\mathbb{P}_{\mathcal{H}_0}\left(n_1 \times M_N \geqslant n_1-k\prime_{\alpha}\right) &lt; \alpha/2\)</span>. Nous prenons alors la décision du test en fonction de la valeur de la réalisation de la statistique du test calculée à l’aide de l’échantillon, <span class="math inline">\(n_1\times M_{N}(obs)\)</span>. Alors, nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ {{n}_{1}}\times {{M}_{N}}(obs)\notin ]{{k}_{\alpha }};{{n}_{1}}-k{{\prime }_{\alpha }}[ &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ {{n}_{1}}\times {{M}_{N}}(obs)\in ]{{k}_{\alpha }};{{n}_{1}}-k{{\prime }_{\alpha }}[ &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span> * Second cas : Les tailles <span class="math inline">\(n_1\)</span> et <span class="math inline">\(n_2\)</span> sont grandes, c’est-à-dire <span class="math inline">\(n_1 \geqslant 25\)</span> et <span class="math inline">\(n_2 \geqslant 25\)</span>. Nous utiliserons alors l’approximation normale avec correction de continuité présentée ci-dessus.</p>
</div>
<div id="remarques-6" class="section level4">
<h4 class="hasAnchor">
<a href="#remarques-6" class="anchor"></a>Remarques :</h4>
<p>Si nous utilisons un logiciel de statistique celui-ci nous fournit une <span class="math inline">\(p\)</span>-valeur. Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ p\text{-valeur}\alpha  &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ p\text{-valeur}&gt;\alpha  &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span> 1. Dans le premier cas, lorsque nous rejetons <span class="math inline">\(\mathcal{H}_0\)</span>, nous décidons que <span class="math inline">\(\mathcal{H}_1\)</span> est vraie avec un risque d’erreur de première espèce au plus égal à <span class="math inline">\(\alpha\)</span>. En effet, le niveau de signification réel du test est égal à <span class="math inline">\(\mathbb{P}_{\mathcal{H}_0}\left(n_1\times M_N \leqslant k_{\alpha}\right)+\mathbb{P}_{\mathcal{H}_0}\left(n_1 \times M_N \geqslant n_1-k\prime_{\alpha}\right)\)</span> qui est généralement strictement inférieur à <span class="math inline">\(\alpha\)</span>. 2. Lorsque nous conservons <span class="math inline">\(\mathcal{H}_0\)</span>, c’est avec un risque d’erreur de deuxième espèce <span class="math inline">\(\beta\)</span>.</p>
</div>
</div>
</div>
<div id="test-de-wilcoxon" class="section level2">
<h2 class="hasAnchor">
<a href="#test-de-wilcoxon" class="anchor"></a>Test de Wilcoxon</h2>
<p>Nous considérons deux variables aléatoires <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> de lois continues, observées toutes les deux sur les mêmes unités d’un échantillon aléatoire de taille <span class="math inline">\(n\)</span>. Nous supposons que la loi de la différence, <span class="math inline">\(X-Y\)</span>, entre les deux variables étudiées <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> est symétrique par rapport à 0. Les observations se présentent alors sous la forme d’une suite de couples <span class="math inline">\((x_1,y_1),\ldots,(x_n,y_n)\)</span>.</p>
<div id="hypothèses-testées-4" class="section level3">
<h3 class="hasAnchor">
<a href="#hypoth%C3%A8ses-test%C3%A9es-4" class="anchor"></a>Hypothèses testées</h3>
<p>Le test de Wilcoxon permet de tester l’hypothèse suivante : <span class="math display">\[{\mathcal{H}}_{0}:\quad\mathbb{E}(X)=\mathbb{E}(Y)\]</span> contre <span class="math display">\[{\mathcal{H}}_{1}:\quad\mathbb{E}(X)\not=\mathbb{E}(Y).\]</span></p>
</div>
<div id="remarque-6" class="section level3">
<h3 class="hasAnchor">
<a href="#remarque-6" class="anchor"></a>Remarque :</h3>
<p>Ce test suppose que la loi de la différence, <span class="math inline">\(X-Y\)</span>, entre les deux variables étudiées <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> est symétrique par rapport à 0. Dans le cas contraire, les hypothèses auxquelles le test permettrait de s’intéresser seraient : <span class="math display">\[{\mathcal{H}}_{0}:\quad \textrm{La loi continue de $X-Y$ est symétrique par rapport à l’origine}\]</span> contre <span class="math display">\[{\mathcal{H}}_{1}:\quad \textrm{La loi continue de $X-Y$ n’est pas symétrique par rapport à l’origine.}\]</span></p>
</div>
<div id="absence-dex-quo-parmi-les-observations-1" class="section level3">
<h3 class="hasAnchor">
<a href="#absence-dex-quo-parmi-les-observations-1" class="anchor"></a>Absence d’ex quo parmi les observations</h3>
<div id="statistique-du-test-5" class="section level4">
<h4 class="hasAnchor">
<a href="#statistique-du-test-5" class="anchor"></a>Statistique du test</h4>
<p>Pour obtenir la statistique du test notée <span class="math inline">\(W_n^+\)</span> en général, nous devons procéder à des calculs successifs : 1. Après avoir calculé les différences <span class="math inline">\(d_i\)</span>, nous classons par ordre croissant les <span class="math inline">\(|d_i|\)</span> non nulles, c’est-à-dire les <span class="math inline">\(d_i\)</span> sans tenir compte des signes. 2. Nous attribuons à chaque <span class="math inline">\(|d_i|\)</span> le rang correspondant. 3. Nous restituons ensuite à chaque rang le signe de la différence correspondante. 4. Enfin, nous calculons la somme <span class="math inline">\(W_n^+\)</span> des rangs positifs (<span class="math inline">\(P\)</span>) et la somme <span class="math inline">\(W_n^-\)</span> des rangs négatifs (<span class="math inline">\(M\)</span>). La somme <span class="math inline">\(W_n^+\)</span> des rangs positifs (<span class="math inline">\(P\)</span>) permet de tester l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span>.</p>
</div>
<div id="règle-de-décision-et-conclusion-du-test-5" class="section level4">
<h4 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test-5" class="anchor"></a>Règle de décision et conclusion du test</h4>
<ul>
<li>Premier cas : La taille <span class="math inline">\(n\)</span> est inférieure strictement à 15. Pour un seuil donné <span class="math inline">\(\alpha\)</span>, nous cherchons, dans les tables de la loi de Wilcoxon, le plus grand nombre entier <span class="math inline">\(k_{\alpha}\)</span> tel que <span class="math inline">\(\mathbb{P}_{\mathcal{H}_0}\left(W_n^{+}\leqslant k_{\alpha}\right)\leqslant \alpha/2\)</span>. Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ W_{n}^{+}(obs)\notin ]{{k}_{\alpha }};n(n+1)/2-{{k}_{\alpha }}[ &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ W_{n}^{+}(obs)\in ]{{k}_{\alpha }};n(n+1)/2-{{k}_{\alpha }}[ &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span>
</li>
<li>Second cas : La taille <span class="math inline">\(n\)</span> est supérieure ou égale à 15. Nous utilisons l’approximation normale avec correction de continuité : <span class="math display">\[\mathbb{P}_{\mathcal{H}_0}\left(W_n^+ \leqslant k\right)=\Phi\left(\frac{2k+1-\displaystyle\frac{n(n+1)}{2}}{\sqrt{\displaystyle\frac{n(n+1)(2n+1)}{6}}}\right)\]</span> où <span class="math inline">\(\Phi\)</span> est la fonction de répartition de la loi normale centrée-réduite et <span class="math inline">\(k\)</span> un nombre entier compris entre 0 et <span class="math inline">\(n\)</span>.</li>
</ul>
<ol style="list-style-type: decimal">
<li>Dans le premier cas, lorsque nous rejetons <span class="math inline">\(\mathcal{H}_0\)</span>, nous décidons que <span class="math inline">\(\mathcal{H}_1\)</span> est vraie avec un risque d’erreur de première espèce au plus égal à <span class="math inline">\(\alpha\)</span>. En effet, le niveau de signification réel du test est égal à <span class="math inline">\(2\mathbb{P}_{\mathcal{H}_0}\left(W_n^{+}\leqslant w_{\alpha}\right)\)</span> qui est généralement strictement inférieur à <span class="math inline">\(\alpha\)</span>.</li>
<li>Lorsque nous conservons <span class="math inline">\(\mathcal{H}_0\)</span>, c’est avec un risque d’erreur de deuxième espèce <span class="math inline">\(\beta\)</span> qui est difficile à évaluer.</li>
</ol>
</div>
</div>
<div id="présence-dex-quo-parmi-les-observations" class="section level3">
<h3 class="hasAnchor">
<a href="#pr%C3%A9sence-dex-quo-parmi-les-observations" class="anchor"></a>Présence d’ex quo parmi les observations</h3>
<p>Ce cas se traite de la même manière que pour la statistique du test des rangs signés de Wilcoxon (voir section correspondante).</p>
</div>
<div id="présence-dobservations-nulles-parmi-les-données-1" class="section level3">
<h3 class="hasAnchor">
<a href="#pr%C3%A9sence-dobservations-nulles-parmi-les-donn%C3%A9es-1" class="anchor"></a>Présence d’observations nulles parmi les données</h3>
<p>Ce cas se traite de la même manière que pour la statistique du test des rangs signés de Wilcoxon (voir section correspondante).</p>
</div>
</div>
<div id="test-dansari-bradley-de-comparaison-de-deux-variances" class="section level2">
<h2 class="hasAnchor">
<a href="#test-dansari-bradley-de-comparaison-de-deux-variances" class="anchor"></a>Test d’Ansari-Bradley de comparaison de deux variances</h2>
<p>Le test d’Ansary-Bradley est basé sur l’étude des rangs observés dans les deux échantillons. Il s’applique en présence de deux variables aléatoires continues quelconques.</p>
<div id="cadre-dapplication" class="section level3">
<h3 class="hasAnchor">
<a href="#cadre-dapplication" class="anchor"></a>Cadre d’application</h3>
<p>Soit <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> deux variables aléatoires continues et <span class="math inline">\(h\)</span> une fonction de densité. Nous notons <span class="math inline">\(f_X\)</span> la fonction de densité de <span class="math inline">\(X\)</span> et <span class="math inline">\(g_Y\)</span> celle de <span class="math inline">\(Y\)</span>. Nous supposons que <span class="math inline">\(f_X(t)=h((t-m)/s)/s\)</span> et <span class="math inline">\(g_Y(t)=h(t-m)\)</span> où <span class="math inline">\(m\)</span> est un paramètre de nuisance et <span class="math inline">\(s\)</span> est le paramètre d’intérêt qui est égal au rapport des paramètres d’échelle des distributions.</p>
<p>Par exemple, si nous appliquons ce test à deux variables qui suivent des lois normales, le rapport des paramètres d’échelle <span class="math inline">\(s\)</span> est égal au rapport des écarts-types de ces deux variables.</p>
</div>
<div id="procédure-de-test" class="section level3">
<h3 class="hasAnchor">
<a href="#proc%C3%A9dure-de-test" class="anchor"></a>Procédure de test</h3>
<div id="hypothèses-testées-5" class="section level4">
<h4 class="hasAnchor">
<a href="#hypoth%C3%A8ses-test%C3%A9es-5" class="anchor"></a>Hypothèses testées</h4>
<p>Le test d’Ansari-Bradley permet de réaliser le test bilatéral sur la valeur du rapport <span class="math inline">\(s\)</span> <span class="math display">\[{\mathcal{H}}_{0}:\quad s=1\]</span> contre <span class="math display">\[{\mathcal{H}}_{1}:\quad s\neq 1\]</span> ou /et les deux tests unilatéraux sur la valeur du rapport <span class="math inline">\(s\)</span> suivants : <span class="math display">\[{\mathcal{H}}_{0}:\quad s=1\]</span> contre <span class="math display">\[{\mathcal{H}}_{1}:\quad s&lt;1\]</span> ou bien <span class="math display">\[{\mathcal{H}}_{0}:\quad s=1\]</span> contre <span class="math display">\[{\mathcal{H}}_{1}:\quad s&gt;1.\]</span></p>
</div>
<div id="conditions-dapplication-du-test" class="section level4">
<h4 class="hasAnchor">
<a href="#conditions-dapplication-du-test" class="anchor"></a>Conditions d’application du test</h4>
<p>Il faut que l’échantillon <span class="math inline">\(x_1,\dots,x_{n_1}\)</span> soit formé des réalisations indépendantes de la variable aléatoire <span class="math inline">\(X\)</span> de densité <span class="math inline">\(f\left( \left( t-m \right)/s \right)/s\)</span> et que le second échantillon <span class="math inline">\(y_1,\dots,y_{n_2}\)</span> soit aussi formé des réalisations indépendantes de la variable aléatoire <span class="math inline">\(Y\)</span> qui suit une loi de densité <span class="math inline">\(f(t-m)\)</span> où <span class="math inline">\(m\)</span> est un paramètre inconnu. De plus, les variables aléatoires <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> doivent être indépendantes. Par contre, les effectifs <span class="math inline">\(n_1\)</span> et <span class="math inline">\(n_2\)</span> ne sont pas forcément égaux.</p>
</div>
<div id="statistique-du-test-6" class="section level4">
<h4 class="hasAnchor">
<a href="#statistique-du-test-6" class="anchor"></a>Statistique du test</h4>
<p>Pour obtenir la statistique <span class="math inline">\(AB_{n_1,n_2}\)</span> du test d’Ansari-Bradley, nous devons procéder à des calculs successifs : 1. Nous classons par ordre croissant l’ensemble des observations des deux échantillons <span class="math inline">\((x_1,\ldots,x_{n_1})\)</span> et <span class="math inline">\((y_1,\ldots,y_{n_2})\)</span> de taille respective <span class="math inline">\(n_1\)</span> et <span class="math inline">\(n_2\)</span>. 2. Nous affectons le rang correspondant en partant de 1 et à partir des deux extrémités en direction du centre de l’échantillon. Si <span class="math inline">\(n_1+n_2\)</span> est pair, nous attribuons donc les rangs suivants :<span class="math inline">\(1,3,5,\ldots,(m+n)/2,(m+n)/2,\ldots,5,3,1\)</span> aux observations. Si <span class="math inline">\(n_1+n_2\)</span> est impair, nous attribuons donc les rangs suivants :<span class="math inline">\(1,3,5,\ldots,(m+n-1)/2,(m+n+1)/2,(m+n-1)/2,\ldots,5,3,1\)</span> aux observations. 3. La réalisation de la statistique <span class="math inline">\(AB_{n_1,n_2}(obs)\)</span> du test d’Ansari-Bradley est égale à la somme des rangs des observations de l’échantillon <span class="math inline">\(x_1,\dots,x_{n_1}\)</span>.</p>
</div>
<div id="propriétés-5" class="section level4">
<h4 class="hasAnchor">
<a href="#propri%C3%A9t%C3%A9s-5" class="anchor"></a>Propriétés :</h4>
<p>Lorsque l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> est vraie, la variable aléatoire <span class="math inline">\(AB_{n_1,n_2}\)</span> a les trois propriétés suivantes : 1. si <span class="math inline">\(n+m\)</span> est pair, <span class="math inline">\(\mathbb{E}\left(AB_{n_1,n_2}\right)=n_1(n_1+n_2+2)/4\)</span> et <span class="math inline">\(\mathrm{Var}\left(AB_{n_1,n_2}\right)=(n_1n_2)(n_1+n_2-2)(n_1+n_2+2)/(48(n_1+n_2-1))\)</span>. 2. si <span class="math inline">\(n+m\)</span> est impair, <span class="math inline">\(\mathbb{E}\left(AB_{n_1,n_2}\right)=n_1(n_1+n_2+1)^2/(4(n_1+n_2))\)</span> et <span class="math inline">\(\mathrm{Var}\left(AB_{n_1,n_2}\right)=(n_1n_2)(n_1+n_2+1)(3+(n_1+n_2)^2)/(48(n_1+n_2)^2)\)</span>. 3. <span class="math inline">\(AB_{n_1,n_2}\)</span> est tabulée pour de faibles valeurs de <span class="math inline">\(n_1\)</span> et de <span class="math inline">\(n_2\)</span>. Pour <span class="math inline">\(n_1&gt; 20\)</span> et <span class="math inline">\(n_2&gt; 20\)</span>, nous utiliserons l’approximation normale avec correction de continuité : <span class="math display">\[\displaystyle\mathbb{P}_{\mathcal{H}_0}\left(AB_{n_1,n_2}\leqslant u\right)=\Phi\left(\frac{u-\mathbb{E}\left(AB_{n_1,n_2}\right)+1/2}{\sqrt{\displaystyle\mathrm{Var}\left(AB_{n_1,n_2}\right)}}\right)\]</span> où <span class="math inline">\(\Phi\)</span> est la fonction de répartition de la loi normale centrée-réduite et <span class="math inline">\(u\)</span> est un nombre entier.</p>
</div>
<div id="règle-de-décision-et-conclusion-du-test-6" class="section level4">
<h4 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test-6" class="anchor"></a>Règle de décision et conclusion du test</h4>
<ul>
<li>Premier cas : Les tailles <span class="math inline">\(n_1\)</span> ou <span class="math inline">\(n_2\)</span> sont inférieures ou égales à <span class="math inline">\(20.\)</span> Pour un seuil donné <span class="math inline">\(\alpha\)</span>, les tables d’Ansari-Bradley nous fournissent deux valeurs critiques <span class="math inline">\(c_{\alpha}\)</span> et <span class="math inline">\(c_{1-\alpha}\)</span>. Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ A{{B}_{{{n}_{1}},{{n}_{2}}}}(obs)\in ]{{c}_{\alpha }};{{c}_{1-\alpha }}[ &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ A{{B}_{{{n}_{1}},{{n}_{2}}}}(obs)\not{\in }]{{c}_{\alpha }};{{c}_{1-\alpha }}[ &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span>
</li>
<li>Second cas : Les tailles <span class="math inline">\(n_1\)</span> et <span class="math inline">\(n_2\)</span> sont supérieures strictement à <span class="math inline">\(20.\)</span> Nous utilisons la statistique <span class="math inline">\(\frac{AB_{n_1,n_2}-\mathbb{E}\left(AB_{n_1,n_2}\right)}{\sqrt{\displaystyle\mathrm{Var}\left(AB_{n_1,n_2}\right)}}\)</span> et l’approximation normale présentée ci-dessus.</li>
</ul>
</div>
<div id="remarque-7" class="section level4">
<h4 class="hasAnchor">
<a href="#remarque-7" class="anchor"></a>Remarque :</h4>
<p>Les tests unilatéraux se déduisent facilement des tests bilatéraux que nous venons d’introduire.</p>
</div>
</div>
</div>
<div id="test-du-coefficient-de-corrélation-de-spearman" class="section level2">
<h2 class="hasAnchor">
<a href="#test-du-coefficient-de-corr%C3%A9lation-de-spearman" class="anchor"></a>Test du coefficient de corrélation de Spearman</h2>
<div id="cadre-dapplication-1" class="section level3">
<h3 class="hasAnchor">
<a href="#cadre-dapplication-1" class="anchor"></a>Cadre d’application</h3>
<p>La mesure de la dépendance au sens de Spearman entre deux variables aléatoires continues <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> est notée <span class="math inline">\(\rho_{\mathcal{S}}(X,Y)\)</span>.</p>
<p>Elle pourra être estimé par la statistique de Spearman <span class="math inline">\(\rho_{\mathcal{S},n}(X,Y)\)</span> définie sur un échantillon aléatoire <span class="math inline">\(((X_1,Y_1),\ldots,(X_n,Y_n))\)</span> suivant la loi de <span class="math inline">\((X,Y)\)</span>. La statistique de Spearman <span class="math inline">\(\rho_{\mathcal{S},n}(X,Y)\)</span> est basée sur l’étude de la corrélation des rangs et est appelée le coefficient de corrélation de Spearman.</p>
<p>Ce coefficient a le même champ d’application que la statistique de Kendall <span class="math inline">\(\tau_n(X,Y)\)</span> (voir correspondante), qui lui est généralement préférée. Elle permet de tester l’indépendance ou de mesurer le degré de dépendance entre deux variables aléatoires appariées continues quelconques.</p>
<div id="remarques-7" class="section level4">
<h4 class="hasAnchor">
<a href="#remarques-7" class="anchor"></a>Remarques :</h4>
<p>La statistique <span class="math inline">\(\rho_{\mathcal{S},n}(X,Y)\)</span> permet de réaliser plusieurs tests bilatéraux et unilatéraux.</p>
</div>
</div>
<div id="le-coefficient-de-corrélation-rho_mathcalsxy-de-spearman" class="section level3">
<h3 class="hasAnchor">
<a href="#le-coefficient-de-corr%C3%A9lation-rho_mathcalsxy-de-spearman" class="anchor"></a>Le coefficient de corrélation <span class="math inline">\(\rho_{\mathcal{S}}(X,Y)\)</span> de Spearman</h3>
<div id="généralités" class="section level4">
<h4 class="hasAnchor">
<a href="#g%C3%A9n%C3%A9ralit%C3%A9s" class="anchor"></a>Généralités</h4>
<p>Le coefficient de corrélation de Spearman est un nombre associé à <span class="math inline">\((X,Y)\)</span> qui sert à mesurer le degré de dépendance qui lie <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span>.</p>
<p>Il peut être défini comme étant le coefficient de corrélation simple du couple aléatoire <span class="math inline">\((F_X(X),G_Y(Y))\)</span>, où <span class="math inline">\(F_X\)</span> est la fonction de répartition de <span class="math inline">\(X\)</span> et <span class="math inline">\(G_Y\)</span> celle de <span class="math inline">\(Y\)</span>.</p>
<p>Il est noté <span class="math inline">\(\rho_{\mathcal{S}}(X,Y)\)</span> et défini par : <span class="math display">\[\rho_{\mathcal{S}}(X,Y)=\rho(F_X(X),G_Y(Y)).\]</span></p>
<p>Il possède les propriétés suivantes :</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(-1\leqslant\rho_{\mathcal{S}}(X,Y)\leqslant 1\)</span>;</li>
<li>« <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> indépendantes » implique <span class="math inline">\(\rho_{\mathcal{S}}(X,Y)=0\)</span>;</li>
<li>
<span class="math inline">\(\rho_{\mathcal{S}}(X,Y)=1\)</span> (respectivement <span class="math inline">\(\rho_{\mathcal{S}}(X,Y)=-1\)</span>) si et seulement si il existe une fonction <span class="math inline">\(\phi\)</span> croissante (respectivement décroissante) de <span class="math inline">\(\mathbb{R}\)</span> dans <span class="math inline">\(\mathbb{R}\)</span> telle que <span class="math inline">\(Y = \phi(X)\)</span>;</li>
<li>si <span class="math inline">\(\phi\)</span> et <span class="math inline">\(\psi\)</span> désignent deux fonctions croissantes de <span class="math inline">\(\mathbb{R}\)</span> dans <span class="math inline">\(\mathbb{R}\)</span> alors <span class="math inline">\(\rho_{\mathcal{S}}(\phi(X),\psi(Y))=\rho_{\mathcal{S}}(X,Y)\)</span>.</li>
</ol>
</div>
<div id="estimation-de-rho_mathcalsxy" class="section level4">
<h4 class="hasAnchor">
<a href="#estimation-de-rho_mathcalsxy" class="anchor"></a>Estimation de <span class="math inline">\(\rho_{\mathcal{S}}(X,Y)\)</span>
</h4>
<p>À chaque couple <span class="math inline">\((x_i,y_i)\)</span> de l’échantillon nous associons le couple d’entiers <span class="math inline">\((r_i,s_i)\)</span> où <span class="math inline">\(r_i\)</span> est le rang de <span class="math inline">\(x_i\)</span> dans <span class="math inline">\(x_1,\ldots,x_n\)</span> et <span class="math inline">\(s_i\)</span> est le rang de <span class="math inline">\(y_i\)</span> dans <span class="math inline">\(y_1,\ldots,y_n\)</span>.</p>
<p>Nous appelons <span class="math inline">\(R_i\)</span> la variable aléatoire associée au rang d’un <span class="math inline">\(X_i\)</span>, et <span class="math inline">\(S_i\)</span> celle associée au rang d’un <span class="math inline">\(Y_i\)</span>, puis nous posons <span class="math inline">\(R=\left(R_1,\ldots,R_n\right)\)</span> et <span class="math inline">\(S=\left(S_1,\ldots,S_n\right)\)</span>. Nous calculons alors simplement le coefficient de corrélation des rangs : <span class="math display">\[\begin{align}
  &amp; {{\rho }_{\mathcal{S},n}}(X,Y)=\widehat{\rho (R,S)}=\frac{\sum\limits_{i=1}^{n}{\left( {{R}_{i}}-\bar{R} \right)\times \left( {{S}_{i}}-\bar{S} \right)}}{\widehat{{{\sigma }_{R}}}\widehat{{{\sigma }_{S}}}}=\frac{12}{{{n}^{3}}-n}\sum\limits_{i=1}^{n}{\left[ \left( {{R}_{i}}-\frac{n+1}{2} \right)\left( {{S}_{i}}-\frac{n+1}{2} \right) \right]} \\ 
 &amp; =1-\frac{6}{{{n}^{3}}-n}\sum\limits_{i=1}^{n}{{{\left( {{R}_{i}}-{{S}_{i}} \right)}^{2}}}.  
\end{align}\]</span></p>
<p>La réalisation <span class="math inline">\(\rho_{\mathcal{S},n}(X,Y)(obs)\)</span> de la statistique <span class="math inline">\(\rho_{\mathcal{S},n}(X,Y)\)</span> sur l’échantillon <span class="math inline">\(((x_1,y_1),\ldots,(x_n,y_n))\)</span> possède les propriétés suivantes :</p>
<ul>
<li>
<span class="math inline">\(-1\leqslant\rho_{\mathcal{S},n}(X,Y)(obs)\leqslant 1\)</span>;</li>
<li>
<span class="math inline">\(\rho_{\mathcal{S},n}(X,Y)(obs)=1\)</span> si et seulement si <span class="math inline">\(\forall i = 1\ldots n, r_i=s_i\)</span>;</li>
<li>
<span class="math inline">\(\rho_{\mathcal{S},n}(X,Y)(obs)=-1\)</span> si et seulement si <span class="math inline">\(\forall i = 1\ldots n, r_i=n+1-s_i\)</span>.</li>
</ul>
<p>Nous introduisons souvent une variable auxiliaire <span class="math inline">\(D^2_{\mathcal{S},n}(X,Y)=\sum_{i=1}^n\left(R_i-S_i\right)^2\)</span>.</p>
<p>Dans certaines tables, nous trouverons les valeurs de <span class="math inline">\(D_{\mathcal{S},n}\)</span>.</p>
<p>Nous avons alors la relation suivante : <span class="math display">\[{{\rho }_{\mathcal{S},n}}(X,Y)=1-\frac{6D_{\mathcal{S},n}^{2}(X,Y)}{{{n}^{3}}-n}.\]</span> La statistique <span class="math inline">\(\rho_{\mathcal{S},n}(X,Y)\)</span> possède les propriétés suivantes :</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\rho_{\mathcal{S},n}(X,Y)\)</span> est un estimateur convergent avec biais de <span class="math inline">\(\rho_{\mathcal{S}}(X,Y)\)</span>. <span class="math display">\[\mathbb{E}\left(\rho_{\mathcal{S},n}(X,Y)\right)=\rho_{\mathcal{S}}(X,Y)+\frac{3\left(\tau(X,Y)-\rho_{\mathcal{S}}(X,Y)\right)}{n+1}.\]</span> Pour la définition de <span class="math inline">\(\tau(X,Y)\)</span>, voir Section 9.3.2(c). Nous notons donc désormais <span class="math inline">\(\rho_{\mathcal{S},n}(X,Y)\)</span> par <span class="math inline">\(\widehat{\rho_{\mathcal{S}}(X,Y)}\)</span>.</li>
<li>Sous l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> « <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes » nous avons :</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>
<span class="math inline">\(\mathbb{E}\left(\widehat{\rho_{\mathcal{S}}(X,Y)}\right)=0\)</span> et <span class="math inline">\(\mathrm{Var}\left(\widehat{\rho_{\mathcal{S}}(X,Y)}\right)=\displaystyle\frac{1}{n-1}\)</span>.</li>
<li>Pour <span class="math inline">\(4\leqslant n \leqslant 19\)</span>, la distribution de <span class="math inline">\(\widehat{\rho_{\mathcal{S}}(X,Y)}\)</span> se déduit de celle de <span class="math inline">\(D_{\mathcal{S},n}^2(X,Y)\)</span> qui est tabulée.</li>
<li>Pour <span class="math inline">\(20\leqslant n \leqslant 30\)</span>, nous utilisons la variable <span class="math inline">\(\displaystyle R_n(X,Y)=\sqrt{n-2}\frac{\widehat{\rho_{\mathcal{S}}(X,Y)}}{\sqrt{1-\widehat{\rho_{\mathcal{S}}(X,Y)}^2}}\)</span> qui suit approximativement la loi de Student à <span class="math inline">\(n-2\)</span> degrés de liberté.</li>
<li>Pour <span class="math inline">\(n&gt;30\)</span>, nous avons l’approximation normale <span class="math inline">\(\sqrt{n-1}\widehat{\rho_{\mathcal{S}}(X,Y)}\approx\mathcal{N}(0;1)\)</span>.</li>
</ol>
</div>
</div>
<div id="procédure-de-test-1" class="section level3">
<h3 class="hasAnchor">
<a href="#proc%C3%A9dure-de-test-1" class="anchor"></a>Procédure de test</h3>
<div id="absence-dex-quo-dans-les-observations" class="section level4">
<h4 class="hasAnchor">
<a href="#absence-dex-quo-dans-les-observations" class="anchor"></a>Absence d’ex quo dans les observations</h4>
<p>La statistique <span class="math inline">\(\widehat{\rho_{\mathcal{S}}(X,Y)}\)</span> permet de tester l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> : « <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendants » contre plusieurs alternatives (cf. supra). <span class="math inline">\({\mathcal{H}}_{0}:\quad X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes contre <span class="math inline">\({\mathcal{H}}_{1}:\quad X\)</span> et <span class="math inline">\(Y\)</span> sont liées</p>
<p>Si nous cherchons un niveau de signification de <span class="math inline">\(\alpha\)</span>, nous cherchons <span class="math inline">\(r_{\alpha}\)</span> tel que : <span class="math display">\[\mathbb{P}\left(\widehat{\rho_{\mathcal{S}}(X,Y)}\geqslant r_{\alpha}\right)\leqslant\frac{\alpha}{2}.\]</span></p>
<p>Nous rejetons l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> si, pour notre échantillon, <span class="math inline">\(\widehat{\rho_{\mathcal{S}}(X,Y)}(obs) \not \in \left]-r_{\alpha},r_{\alpha}\right[\)</span>. <span class="math inline">\({\mathcal{H}}_{0}:\quad X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes contre <span class="math inline">\({\mathcal{H}}_{1}:\quad \rho_{\mathcal{S}}(X,Y)&gt;0\)</span>, i.e. les valeurs prises par <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> ont tendance à être concordantes</p>
<p>Si nous cherchons un niveau de signification de <span class="math inline">\(\alpha\)</span>, nous cherchons <span class="math inline">\(r_{\alpha}\)</span> tel que : <span class="math display">\[\mathbb{P}\left(\widehat{\rho_{\mathcal{S}}(X,Y)}\geqslant r_{\alpha}\right)\leqslant\alpha.\]</span></p>
<p>Nous rejetons l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> si, pour notre échantillon, <span class="math inline">\(\widehat{\rho_{\mathcal{S}}(X,Y)}(obs) \geqslant r_{\alpha}\)</span>. <span class="math inline">\({\mathcal{H}}_{0}:\quad X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes contre <span class="math inline">\({\mathcal{H}}_{1}:\quad \rho_{\mathcal{S}}(X,Y)&lt;0\)</span>, i.e. les valeurs prises par <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> ont tendance à être discordantes</p>
<p>Si nous cherchons un niveau de signification de <span class="math inline">\(\alpha\)</span>, nous cherchons <span class="math inline">\(r_{\alpha}\)</span> tel que : <span class="math display">\[\mathbb{P}\left(\widehat{\rho_{\mathcal{S}}(X,Y)}\leqslant r_{\alpha}\right)\leqslant\alpha.\]</span></p>
<p>Nous rejetons l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> si, pour notre échantillon, <span class="math inline">\(\widehat{\rho_{\mathcal{S}}(X,Y)}(obs) \leqslant r_{\alpha}\)</span>.</p>
</div>
<div id="présence-dex-quo-dans-les-observations" class="section level4">
<h4 class="hasAnchor">
<a href="#pr%C3%A9sence-dex-quo-dans-les-observations" class="anchor"></a>Présence d’ex quo dans les observations</h4>
<p>Voici maintenant une statistique corrigée <span class="math inline">\(\rho_{\mathcal{S},n}^{\star}\)</span> adaptée au cas où les variables ne sont pas continues ou au cas où nous avons observé des ex quo.</p>
<p>Nous nous donnons un échantillon formé des réalisations d’un échantillon aléatoire distribué suivant la loi de <span class="math inline">\((X,Y)\)</span>.</p>
<p>Les <span class="math inline">\(n\)</span> valeurs observées <span class="math inline">\(x_1,\ldots,x_n\)</span> sont regroupées en <span class="math inline">\(h\)</span> classes d’ex quo <span class="math inline">\(C_1,\ldots,C_h\)</span>. Certaines de ces classes peuvent ne comporter qu’un seul élément, si cet élément n’a pas d’ex quo. Nous regroupons de même les valeurs <span class="math inline">\(y_i\)</span> en <span class="math inline">\(k\)</span> classes d’ex quo <span class="math inline">\(C_i\prime\)</span>. Au couple de rangs réels <span class="math inline">\((r_i,s_i)\)</span> associé à <span class="math inline">\((x_i,y_i)\)</span> nous substituons le couple de rangs fictifs <span class="math inline">\((r_i^{\star},s_i^{\star})\)</span> où <span class="math inline">\(r_i^{\star}\)</span> est le rang moyen du groupe d’ex quo auquel appartient <span class="math inline">\(x_i\)</span> et <span class="math inline">\(s_i^{\star}\)</span> est le rang moyen du groupe d’ex quo auquel appartient <span class="math inline">\(y_i\)</span>. Nous notons <span class="math inline">\(d_i=\mathrm{Card}(C_i)\)</span> et <span class="math inline">\(d_i\prime =\mathrm{Card}(C_i\prime)\)</span>.</p>
<p>Nous calculons alors <span class="math inline">\(\delta(obs)=\sum_{i=1}^n{(d_i^3-d_i)}\)</span> et <span class="math inline">\(\delta\prime (obs)=\sum_{i=1}^n{((d_i\prime)^{3}-d_i\prime)}\)</span>.</p>
<p>Dans le cas d’ex quo, la valeur prise par la statistique <span class="math inline">\(\rho_{\mathcal{S},n}^{\star}\)</span> est égale à : <span class="math display">\[\begin{align}
  &amp; \rho _{\mathcal{S},n}^{\star }(X,Y)(obs)=\frac{12}{\sqrt{({{n}^{3}}-n-\delta )({{n}^{3}}-n-\delta \prime )}}\sum\limits_{i=1}^{n}{\left[ \left( r_{i}^{\star }-\frac{n+1}{2} \right)\left( s_{i}^{\star }-\frac{n+1}{2} \right) \right]} \\ 
 &amp; =\frac{12\sum\limits_{i=1}^{n}{\left( r_{i}^{\star }\times s_{i}^{\star } \right)}-3n{{(n+1)}^{2}}}{\sqrt{({{n}^{3}}-n-\delta )({{n}^{3}}-n-\delta \prime )}}.  
\end{align}\]</span> <span class="math inline">\(\rho_{\mathcal{S},n}^{\star}(X,Y)\)</span> est donc la variable aléatoire associée à <span class="math inline">\(\rho_{\mathcal{S},n}^{\star}(X,Y)(obs)\)</span>.</p>
<p>Lorsque <span class="math inline">\(n&gt;20\)</span> et <span class="math inline">\((\delta(obs)+\delta\prime (obs))/n^3&lt;0,1\)</span> nous utilisons l’approximation normale : <span class="math display">\[\sqrt{n-1}\rho_{\mathcal{S},n}(X,Y)^{\star}\approx\mathcal{N}(0;1).\]</span> Dans les autres situations, il n’y a pas de table numérique.</p>
</div>
</div>
</div>
<div id="test-du-coefficient-de-corrélation-de-kendall" class="section level2">
<h2 class="hasAnchor">
<a href="#test-du-coefficient-de-corr%C3%A9lation-de-kendall" class="anchor"></a>Test du coefficient de corrélation de Kendall</h2>
<div id="cadre-dapplication-2" class="section level3">
<h3 class="hasAnchor">
<a href="#cadre-dapplication-2" class="anchor"></a>Cadre d’application</h3>
<p>La mesure de la dépendance au sens de Kendall entre deux variables aléatoires continues <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sera notée <span class="math inline">\(\tau(X,Y)\)</span>.</p>
<p>Ce nombre pourra être estimé par la statistique de Kendall <span class="math inline">\(\tau_n\)</span> définie sur un échantillon <span class="math inline">\(((X_1,Y_1),\ldots,(X_n,Y_n))\)</span> indépendant et identiquement distribué.</p>
<p>La statistique <span class="math inline">\(\tau_n\)</span> permet de réaliser plusieurs tests bilatéraux et unilatéraux.</p>
</div>
<div id="le-coefficient-de-corrélation-tauxy-de-kendall" class="section level3">
<h3 class="hasAnchor">
<a href="#le-coefficient-de-corr%C3%A9lation-tauxy-de-kendall" class="anchor"></a>Le coefficient de corrélation <span class="math inline">\(\tau(X,Y)\)</span> de Kendall</h3>
<p>Considérons deux paires <span class="math inline">\((x_i,y_i)\)</span> et <span class="math inline">\((x_j,y_j)\)</span> issues d’une réalisation de l’échantillon <span class="math inline">\(((X_1,Y_1)\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\((X_n,Y_n))\)</span>.</p>
<p>Elles sont dites : * concordantes si <span class="math inline">\((x_i-x_j)(y_i-y_j)&gt;0\)</span>, c’est-à-dire si nous avons simultanément <span class="math inline">\((x_i&gt;x_j)\)</span> et <span class="math inline">\((y_i&gt;y_j)\)</span> ou <span class="math inline">\((x_i&lt;x_j)\)</span> et <span class="math inline">\((y_i&lt;y_j)\)</span>. * discordantes si <span class="math inline">\((x_i-x_j)(y_i-y_j)&lt;0\)</span>, c’est-à-dire si nous avons simultanément <span class="math inline">\((x_i&gt;x_j)\)</span> et <span class="math inline">\((y_i&lt;y_j)\)</span> ou <span class="math inline">\((x_i&lt;x_j)\)</span> et <span class="math inline">\((y_i&gt;y_j)\)</span>. Considérons deux couples de variables aléatoires <span class="math inline">\((X_1,Y_1)\)</span> et <span class="math inline">\((X_2,Y_2)\)</span> de même loi que celle du couple étudié <span class="math inline">\((X,Y)\)</span>. Une concordance parfaite est telle que <span class="math inline">\(X_2&gt;X_1 \ \Leftrightarrow \ Y_2&gt;Y_1\)</span>, c’est-à-dire : [((X_2&gt;X_1)(Y_2&gt;Y_1))+((X_2&lt;X_1)(Y_2&lt;Y_1))=1</p>
<p>   ((X_2-X_1)(Y_2-Y_1)&gt;0)=1.] Une discordance parfaite est telle que <span class="math inline">\(X_2&gt;X_1 \ \Leftrightarrow \ Y_2&lt;Y_1\)</span>, c’est-à-dire : [((X_2&gt;X_1)(Y_2&lt;Y_1))+((X_2&lt;X_1)(Y_2&gt;Y_1))=1</p>
<p>   ((X_2-X_1)(Y_2-Y_1)&lt;0)=1.] Nous introduisons donc <span class="math inline">\(\tau^+(X,Y)\)</span> et <span class="math inline">\(\tau^-(X,Y)\)</span> qui mesurent respectivement la concordance et la discordance du couple <span class="math inline">\((X,Y)\)</span> : <span class="math display">\[\begin{align}
  &amp; {{\tau }^{+}}(X,Y)=\mathbb{P}\left( ({{X}_{2}}-{{X}_{1}})({{Y}_{2}}-{{Y}_{1}})&gt;0 \right) \\ 
 &amp; {{\tau }^{-}}(X,Y)=\mathbb{P}\left( ({{X}_{2}}-{{X}_{1}})({{Y}_{2}}-{{Y}_{1}})&lt;0 \right).  
\end{align}\]</span></p>
<p>Le coefficient <span class="math inline">\(\tau(X,Y)\)</span> de Kendall est défini par : <span class="math display">\[\tau (X,Y)={{\tau }^{+}}(X,Y)-{{\tau }^{-}}(X,Y).\]</span></p>
<p>Il mesure le degré de concordance si <span class="math inline">\(\tau(X,Y)&gt;0\)</span>, ou, au contraire, le degré de discordance si <span class="math inline">\(\tau(X,Y)&lt;0\)</span> et possède les propriétés suivantes :</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(-1\leqslant\tau(X,Y)\leqslant 1\)</span>;</li>
<li>si les variables aléatoires <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes alors <span class="math inline">\(\tau(X,Y)=0\)</span>;</li>
<li>
<span class="math inline">\(\tau(X,Y)=1\)</span> (resp. <span class="math inline">\(\tau(X,Y)=-1\)</span>) si et seulement si il existe une fonction <span class="math inline">\(\phi\)</span> croissante (resp. décroissante) de <span class="math inline">\(\mathbb{R}\)</span> dans <span class="math inline">\(\mathbb{R}\)</span> telle que <span class="math inline">\(Y = \phi(X)\)</span>;</li>
<li>si <span class="math inline">\(\phi\)</span> et <span class="math inline">\(\psi\)</span> désignent deux fonctions croissantes de <span class="math inline">\(\mathbb{R}\)</span> dans <span class="math inline">\(\mathbb{R}\)</span> alors <span class="math inline">\(\tau(\phi(X),\psi(Y))=\tau(X,Y)\)</span>;</li>
<li>si <span class="math inline">\((X,Y)\)</span> suit une loi normale bivariée alors <span class="math inline">\(\tau(X,Y)\)</span> et <span class="math inline">\(\rho(X,Y)\)</span> sont liés par la relation : <span class="math inline">\(\rho(X,Y)=\sin{\left(\pi/2 \times \tau(X,Y)\right)}\)</span>.</li>
</ol>
</div>
<div id="estimation-de-tauxy" class="section level3">
<h3 class="hasAnchor">
<a href="#estimation-de-tauxy" class="anchor"></a>Estimation de <span class="math inline">\(\tau(X,Y)\)</span>
</h3>
<p>L’estimation se fait de manière « naturelle » : nous commençons par compter le nombre de paires de couples concordants <span class="math inline">\(c\)</span> et le nombre de paires de couples discordants <span class="math inline">\(d\)</span> dans l’échantillon <span class="math inline">\((x_1,y_1),\ldots,(x_n,y_n)\)</span>.</p>
<p>Il apparaît ici une difficulté supplémentaire par rapport à la théorie. En effet, la loi de <span class="math inline">\((X,Y)\)</span> est continue ; donc la probabilité que <span class="math inline">\(X_1=X_2\)</span> ou que <span class="math inline">\(Y_1=Y_2\)</span> est nulle.</p>
<p>Mais dans l’échantillon il se peut néanmoins que nous observions plusieurs fois la même valeur. Nous notons alors <span class="math inline">\(e\)</span> le nombre de ces paires de couples. Ce sont celles pour lesquelles nous avons <span class="math inline">\((x_j-x_i)(y_j-y_i)=0\)</span>. Dans un premier temps, nous supposerons qu’il n’y a pas d’ex quo. <span class="math display">\[\begin{align}
  &amp; c=\text{le nombre de paires de couples }({{x}_{i}},{{y}_{i}}),({{y}_{i}},{{y}_{j}})\text{ tels que }({{x}_{j}}-{{x}_{i}})({{y}_{j}}-{{y}_{i}})&gt;0\text{ avec }1i&lt;jn. \\ 
 &amp; d=\text{le nombre de paires de couples }({{x}_{i}},{{y}_{i}}),({{y}_{i}},{{y}_{j}})\text{ tels que }({{x}_{j}}-{{x}_{i}})({{y}_{j}}-{{y}_{i}})&lt;0\text{ avec }1i&lt;jn. \\ 
 &amp; e=\text{le nombre de paires de couples }({{x}_{i}},{{y}_{i}}),({{y}_{i}},{{y}_{j}})\text{ tels que }({{x}_{j}}-{{x}_{i}})({{y}_{j}}-{{y}_{i}})=0\text{ avec }1i&lt;jn.  
\end{align}\]</span> Rappelons que pour le moment, nous supposons que <span class="math inline">\(e=0\)</span>. Toute paire de couples est forcément du type <span class="math inline">\(c\)</span> ou du type <span class="math inline">\(d\)</span> et ainsi <span class="math inline">\(c+d=n(n-1)/2\)</span> qui est le nombre total de paires de couples qu’il est possible de faire.</p>
<p>Nous notons <span class="math inline">\(C_n\)</span>, <span class="math inline">\(D_n\)</span> et <span class="math inline">\(E_n\)</span> les variables aléatoires associées à <span class="math inline">\(c\)</span>, <span class="math inline">\(d\)</span> et <span class="math inline">\(e\)</span> et nous définissons alors : <span class="math display">\[{{\tau }_{n}}(X,Y)=\frac{2{{C}_{n}}-\frac{n(n-1)}{2}}{\frac{n(n-1)}{2}}=\frac{4{{C}_{n}}}{n(n-1)}-1.\]</span></p>
<p>Sous l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> « <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes », la distribution de <span class="math inline">\(\tau_n\)</span> a les propriétés suivantes :</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(-1\leqslant\tau_n\leqslant 1\)</span> ; une valeur proche de 1 suggère une forte concordance entre les valeurs prises par <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span>tandis qu’une valeur proche de -1 suggère une forte discordance entre les valeurs prises par <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span>.</li>
<li>
<span class="math inline">\(\tau_n(X,Y)\)</span> est un estimateur sans biais et convergent de <span class="math inline">\(\tau(X,Y)\)</span>. Nous le notons donc désormais <span class="math inline">\(\tau_n(X,Y)=\widehat{\tau(X,Y)}\)</span>.</li>
<li>Sous l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> « <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes », la distribution de <span class="math inline">\(\widehat{\tau(X,Y)}\)</span> a les caractéristiques suivantes :</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>
<span class="math inline">\(\mathbb{E}\left(\widehat{\tau(X,Y)}\right)=0\)</span> et <span class="math inline">\(\mathrm{Var}\left(\widehat{\tau(X,Y)}\right)=\displaystyle\frac{2(2n+5)}{9n(n-1)}\)</span>,</li>
<li>
<span class="math inline">\(\frac{\widehat{\tau(X,Y)}}{\sqrt{\mathrm{Var}\left(\widehat{\tau(X,Y)}\right)}}\approx\mathcal{N}(0;1)\)</span>.</li>
</ol>
<p>Pour réaliser des tests avec des effectifs inférieurs à 20, nous nous reporterons donc à des tables spécifiques ou nous utiliserons un logiciel disposant de statistiques exactes.</p>
</div>
<div id="procédure-de-test-2" class="section level3">
<h3 class="hasAnchor">
<a href="#proc%C3%A9dure-de-test-2" class="anchor"></a>Procédure de test</h3>
<div id="absence-dex-quo-dans-les-observations-1" class="section level4">
<h4 class="hasAnchor">
<a href="#absence-dex-quo-dans-les-observations-1" class="anchor"></a>Absence d’ex quo dans les observations</h4>
<p>La statistique <span class="math inline">\(\widehat{\tau_(X,Y)}\)</span> permet de tester l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> : « <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes » contre plusieurs alternatives (cf. supra). <span class="math inline">\({\mathcal{H}}_{0}:\quad X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes contre <span class="math inline">\({\mathcal{H}}_{1}:\quad X\)</span> et <span class="math inline">\(Y\)</span> sont liées</p>
<p>Si nous cherchons un niveau de signification de <span class="math inline">\(\alpha\)</span>, nous cherchons <span class="math inline">\(t_{\alpha}\)</span> tel que : <span class="math display">\[\mathbb{P}\left(\widehat{\tau(X,Y)}\geqslant t_{\alpha}\right)\leqslant\frac{\alpha}{2}.\]</span></p>
<p>Nous rejetons l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> si <span class="math inline">\(\widehat{\tau(X,Y)} \not \in \left]-t_{\alpha},t_{\alpha}\right[\)</span>. <span class="math inline">\({\mathcal{H}}_{0}:\quad X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes contre <span class="math inline">\({\mathcal{H}}_{1}:\quad \tau(X,Y)&gt;0\)</span>, i.e. les valeurs prises par <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> ont tendance à être concordantes</p>
<p>Si nous cherchons un niveau de signification de <span class="math inline">\(\alpha\)</span>, nous cherchons <span class="math inline">\(t_{\alpha}\)</span> tel que : <span class="math display">\[\mathbb{P}\left(\widehat{\tau(X,Y)}\geqslant t_{\alpha}\right)\leqslant\alpha.\]</span></p>
<p>Nous rejetons l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> si <span class="math inline">\(\widehat{\tau(X,Y)} \geqslant t_{\alpha}\)</span>. <span class="math inline">\({\mathcal{H}}_{0}:\quad X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes contre <span class="math inline">\({\mathcal{H}}_{1}:\quad \tau(X,Y)&lt;0\)</span>, i.e. les valeurs prises par <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> ont tendance à être discordantes Si nous cherchons un niveau de signification de <span class="math inline">\(\alpha\)</span>, nous cherchons <span class="math inline">\(t_{\alpha}\)</span> tel que : <span class="math display">\[\mathbb{P}\left(\widehat{\tau(X,Y)}\leqslant t_{\alpha}\right)\leqslant\alpha.\]</span></p>
<p>Nous rejetons l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> si <span class="math inline">\(\widehat{\tau(X,Y)} \leqslant t_{\alpha}\)</span>.</p>
</div>
<div id="présence-dex-quo-dans-les-observations-1" class="section level4">
<h4 class="hasAnchor">
<a href="#pr%C3%A9sence-dex-quo-dans-les-observations-1" class="anchor"></a>Présence d’ex quo dans les observations</h4>
<p>Voici maintenant une statistique corrigée <span class="math inline">\(\tau_n^{\star}\)</span> adaptée au cas où les variables ne sont pas continues ou au cas où nous avons observé des ex quo.</p>
<p>Les <span class="math inline">\(n\)</span> valeurs observées <span class="math inline">\(x_1,\ldots,x_n\)</span> sont regroupées en <span class="math inline">\(h\)</span> classes d’ex quo <span class="math inline">\(C_1,\ldots,C_h\)</span>. Certaines de ces classes peuvent ne comporter qu’un seul élément, si cet élément n’a pas d’ex quo. Nous regroupons de même les valeurs <span class="math inline">\(y_j\)</span> en <span class="math inline">\(k\)</span> classes d’ex quo <span class="math inline">\(C_j\prime\)</span>.</p>
<p>Nous notons <span class="math inline">\(d_i=\mathrm{Card}(C_i)\)</span> et <span class="math inline">\(d_j\prime =\mathrm{Card}(C_j\prime)\)</span>. Enfin <span class="math inline">\(d=\sum_{i=1}^h{d_i(d_i-1)}\)</span> et <span class="math inline">\(d\prime =\sum_{j=1}^k{d_j\prime (d_j\prime -1)}\)</span>.</p>
<p>Nous calculons alors : <span class="math display">\[{{s}^{\star }}=1\times \text{Nombre de concordants}+(-1)\times \text{Nombre de discordants}+0\times \text{Nombre de cas d }\!\!'\!\!\text{  }\!\!\acute{\mathrm{e}}\!\!\text{ galit }\!\!\acute{\mathrm{e}}\!\!\text{ }.\]</span></p>
<p>Puis nous posons : <span class="math display">\[{{\tau }^{\star }}=\frac{2{{s}^{\star }}}{\sqrt{(n(n-1)-d)(n(n-1)-d\prime )}}.\]</span> <span class="math inline">\(\tau_n^{\star}\)</span> est alors la variable aléatoire associée à <span class="math inline">\(\tau^{\star}\)</span> et <span class="math inline">\(S_n^{\star}\)</span> celle associée à <span class="math inline">\(s^{\star}\)</span>.</p>
<p>Lorsque <span class="math inline">\(n&gt;10\)</span>, <span class="math inline">\(d/n^2&lt;0,1\)</span> et <span class="math inline">\(d\prime /n^2&lt;0,1\)</span> nous utilisons l’approximation normale : <span class="math display">\[\frac{\sqrt{18}S^{\star}_n}{\sqrt{n(n-1)(2n+5)-\delta-\delta\prime }}\approx\mathcal{N}(0;1)\]</span> où <span class="math inline">\(\delta=\sum_{i=1}^h{d_i(d_i-1)(2d_i+5)}\)</span> et <span class="math inline">\(\delta\prime =\sum_{j=1}^k{d_j\prime (d_j\prime -1)(2d_j\prime +5)}\)</span>.</p>
</div>
</div>
</div>
</div>
<div id="compléments--analyse-de-la-variance-des-rangs" class="section level1">
<h1 class="hasAnchor">
<a href="#compl%C3%A9ments--analyse-de-la-variance-des-rangs" class="anchor"></a>Compléments. Analyse de la variance des rangs</h1>
<div id="test-de-kruskal-wallis--comparaisons-multiples-" class="section level2">
<h2 class="hasAnchor">
<a href="#test-de-kruskal-wallis--comparaisons-multiples-" class="anchor"></a>Test de Kruskal-Wallis. Comparaisons multiples.</h2>
<div id="contexte-du-test" class="section level3">
<h3 class="hasAnchor">
<a href="#contexte-du-test" class="anchor"></a>Contexte du test</h3>
<div id="conditions-dapplication" class="section level4">
<h4 class="hasAnchor">
<a href="#conditions-dapplication" class="anchor"></a>Conditions d’application</h4>
<p>Nous observons, de manière indépendante, une variable aléatoire <span class="math inline">\(X\)</span> de loi continue sur <span class="math inline">\(k\geqslant 3\)</span> populations ou sur une population divisée en <span class="math inline">\(k\geqslant 3\)</span> sous-populations. Nous supposons ainsi que nous disposons de <span class="math inline">\(k\)</span> échantillons aléatoires indépendants <span class="math inline">\((X_{1,1},\ldots,X_{1,n_1})\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\((X_{k,1},\ldots,X_{k,n_k})\)</span> et de <span class="math inline">\(k\geqslant 3\)</span> séries d’observations <span class="math inline">\((x_{1,1}\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(x_{1,n_1})\)</span> pour la première, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\((x_{k,1}\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(x_{k,n_k})\)</span> pour la dernière. Nous notons <span class="math inline">\(\mathcal{L}_i(X)\)</span> la loi de la variable aléatoire <span class="math inline">\(X\)</span> sur la (sous-)population d’ordre <span class="math inline">\(i\)</span> avec <span class="math inline">\(1\leqslant i\leqslant k\)</span>. Sans faire d’hypothèses spécifiques, le test de Kruskal-Wallis ne permet pas de tester l’égalité des moyennes ni celle des médianes.</p>
</div>
<div id="hypothèses-du-test" class="section level4">
<h4 class="hasAnchor">
<a href="#hypoth%C3%A8ses-du-test" class="anchor"></a>Hypothèses du test</h4>
<p>Le test de Kruskal-Wallis est utilisé pour tester les hypothèses suivantes : <span class="math inline">\({\mathcal{H}}_{0}:\quad \mathcal{L}_1(X)=\cdots=\mathcal{L}_i(X)=\cdots=\mathcal{L}_k(X)\)</span> contre <span class="math inline">\({\mathcal{H}}_{1}:\quad\)</span>Les lois <span class="math inline">\(\mathcal{L}_1(X)\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(\mathcal{L}_k(X)\)</span> ne sont pas toutes identiques</p>
</div>
</div>
<div id="absence-dex-quo-dans-les-observations-2" class="section level3">
<h3 class="hasAnchor">
<a href="#absence-dex-quo-dans-les-observations-2" class="anchor"></a>Absence d’ex quo dans les observations</h3>
<div id="statistique-de-test" class="section level4">
<h4 class="hasAnchor">
<a href="#statistique-de-test" class="anchor"></a>Statistique de test</h4>
<p>Calculons le rang <span class="math inline">\(R_{i,j}\)</span> de <span class="math inline">\(X_{i,j}\)</span> parmi les <span class="math inline">\(n_{\bullet}\)</span> valeurs, puis la somme des rangs associée à chaque échantillon : <span class="math inline">\(R_{i,\bullet}=\sum_{j=1}^{n_i}R_{i,j}\)</span> et enfin la moyenne des rangs de chaque échantillon : <span class="math inline">\(\overline{R_{i,\bullet}}={R_{i,\bullet}}/{n_{i}}\)</span>. La statistique de Kruskal-Wallis <span class="math inline">\(KW_{n_{\bullet}}\)</span> prend en compte l’écart entre la moyenne des rangs de chaque échantillon et la moyenne de tous les rangs, qui vaut <span class="math inline">\((n_{\bullet}+1)/2\)</span> : <span class="math display">\[K{{W}_{{{n}_{\bullet }}}}=\frac{12}{{{n}_{\bullet }}({{n}_{\bullet }}+1)}\sum\limits_{i=1}^{k}{{{n}_{i}}{{\left( \overline{{{r}_{i,\bullet }}}-\frac{{{n}_{\bullet }}+1}{2} \right)}^{2}}}=\frac{12}{{{n}_{\bullet }}({{n}_{\bullet }}+1)}\sum\limits_{i=1}^{k}{\frac{{{r}_{i,\bullet }}^{2}}{{{n}_{i}}}}-3({{n}_{\bullet }}+1).\]</span></p>
</div>
<div id="propriétés-6" class="section level4">
<h4 class="hasAnchor">
<a href="#propri%C3%A9t%C3%A9s-6" class="anchor"></a>Propriétés :</h4>
<p>Lorsque l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> est vraie, la variable aléatoire <span class="math inline">\(KW_{n_{\bullet}}\)</span> a les trois propriétés suivantes : 1. Pour <span class="math inline">\(i=1,\ldots,k\)</span>, <span class="math inline">\(W_i=n_i\overline{R_{i,\bullet}}\)</span> est la statistique de Wilcoxon qui compare le <span class="math inline">\(i-\)</span>ème traitement aux <span class="math inline">\(k-1\)</span> autres traitements. Sous l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span>, nous en déduisons que <span class="math inline">\(\mathbb{E}\left(W_i\right)=n_i(n_{\bullet}+1)/2\)</span> et <span class="math inline">\(\mathrm{Var}\left(W_i\right)=n_i (n_{\bullet}-n_i) (n_{\bullet}+1)/12\)</span>. Par conséquent, nous avons : <span class="math display">\[KW_{n_{\bullet}}=\frac{1}{n_{\bullet}}\sum_{i=1}^k(n_{\bullet}-n_i)\frac{\left(W_i-\mathbb{E}\left(W_i\right)\right)^2}{\mathrm{Var}\left(W_i\right)}\cdot\]</span> Nous calculons alors l’espérance et la variance de <span class="math inline">\(KW_{n_{\bullet}}\)</span> sous l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> : <span class="math display">\[\mathbb{E}\left( K{{W}_{{{n}_{\bullet }}}} \right)=k-1,\text{Var}\left( K{{W}_{{{n}_{\bullet }}}} \right)=2(k-1)-\frac{2\left[ 3{{k}^{2}}-6k+{{n}_{\bullet }}(2{{k}^{2}}-6k+1) \right]}{5{{n}_{\bullet }}({{n}_{\bullet }}+1)}-\frac{6}{5}\sum\limits_{i=1}^{k}{\frac{1}{{{n}_{i}}}}\]</span> 2. Il est possible de déterminer la distribution de <span class="math inline">\(KW_{n_{\bullet}}\)</span> bien que le calcul soit complexe. Elle est tabulée pour les faibles valeurs des <span class="math inline">\(n_i\)</span>.</p>
</div>
</div>
<div id="règle-de-décision-et-conclusion-du-test-7" class="section level3">
<h3 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test-7" class="anchor"></a>Règle de décision et conclusion du test</h3>
<ul>
<li>Premier cas : L’un des effectifs <span class="math inline">\(n_i\)</span>, <span class="math inline">\(1\leqslant i\leqslant k\)</span>, est inférieur ou égal à 4. Pour un seuil donné <span class="math inline">\(\alpha\)</span>, des tables de la loi de Kuskal-Wallis nous fournissent une valeur critique <span class="math inline">\(c_{\alpha}\)</span>. Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ K{{W}_{{{n}_{\bullet }}}}(obs){{c}_{\alpha }} &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ K{{W}_{{{n}_{\bullet }}}}(obs)&lt;{{c}_{\alpha }} &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span> Le niveau de signification réel du test est généralement strictement inférieur à <span class="math inline">\(\alpha\)</span>.</li>
<li>Second cas : Si <span class="math inline">\(n_i \geqslant 5\)</span>, pour tout <span class="math inline">\(1\leqslant i \leqslant k\)</span>, nous utilisons l’approximation <span class="math inline">\(KW_{n_{\bullet}} \approx \chi^2(k-1)\)</span>. Pour un seuil donné <span class="math inline">\(\alpha\)</span>, des tables de la loi du <span class="math inline">\(\chi^2\)</span> nous fournissent une valeur critique <span class="math inline">\(c_{\alpha}\)</span> telle que <span class="math inline">\(\mathbb{P}_{\mathcal{H}_0}\left(-c_{\alpha} &lt; Z_{n_1,n_2} &lt; c_{\alpha}\right)=1-\alpha\)</span>. Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ K{{W}_{{{n}_{\bullet }}}}(obs){{c}_{\alpha }} &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ K{{W}_{{{n}_{\bullet }}}}(obs)&lt;{{c}_{\alpha }} &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span> Lorsque nous rejetons <span class="math inline">\(\mathcal{H}_0\)</span>, nous décidons que <span class="math inline">\(\mathcal{H}_1\)</span> est vraie avec un risque d’erreur de première espèce <span class="math inline">\(\alpha\)</span>. Lorsque nous conservons <span class="math inline">\(\mathcal{H}_0\)</span>, c’est avec un risque d’erreur de deuxième espèce <span class="math inline">\(\beta\)</span>.</li>
</ul>
</div>
<div id="présence-dex-quo-dans-les-observations-la-méthode-des-rangs-moyens" class="section level3">
<h3 class="hasAnchor">
<a href="#pr%C3%A9sence-dex-quo-dans-les-observations-la-m%C3%A9thode-des-rangs-moyens" class="anchor"></a>Présence d’ex quo dans les observations : la méthode des rangs moyens</h3>
<p>À chaque nombre appartenant à un groupe d’ex quo, nous attribuons le rang moyen du groupe auquel il appartient puis nous déterminons la somme <span class="math inline">\(T=\sum_{l=1}^h(t_l^3-t_l)\)</span> où <span class="math inline">\(t_l\)</span> désigne le nombre d’éléments du <span class="math inline">\(l-\)</span>ème groupe d’ex quo. Il est d’usage de substituer à <span class="math inline">\(KW_{n_{\bullet}}\)</span> la variable <span class="math inline">\(KW_{n_{\bullet}}^{\star}\)</span> définie par : <span class="math display">\[KW_{n_{\bullet}}^{\star}=\displaystyle\frac{KW_{n_{\bullet}}}{\displaystyle 1-\frac{T}{n_{\bullet}^3-n_{\bullet}}}.\]</span></p>
</div>
<div id="comparaisons-multiples" class="section level3">
<h3 class="hasAnchor">
<a href="#comparaisons-multiples" class="anchor"></a>Comparaisons multiples</h3>
<div id="test-de-steel-dwass-critchlow-fligner" class="section level4">
<h4 class="hasAnchor">
<a href="#test-de-steel-dwass-critchlow-fligner" class="anchor"></a>Test de Steel-Dwass-Critchlow-Fligner</h4>
<p><span class="math inline">\(W_{n_i,n_{i\prime}}\)</span> est la statistique de Wilcoxon qui compare le <span class="math inline">\(i-\)</span>ème traitement au <span class="math inline">\(i\prime -\)</span>ème traitement (voir Section 9.3.1(b)). Les observations des deux groupes <span class="math inline">\(i\)</span> et <span class="math inline">\(i\prime\)</span> sont ordonnées puis regroupées en <span class="math inline">\(h\)</span> classes d’ex quo <span class="math inline">\(C_j\)</span>, <span class="math inline">\(1\leqslant j \leqslant h\)</span>. Notons <span class="math inline">\(d_j\)</span> le nombre d’ex quo de la classe <span class="math inline">\(C_j\)</span> et <span class="math inline">\(m_{i,i\prime }=n_i+n_{i\prime }\)</span>. Nous décidons qu’au seuil global <span class="math inline">\(\boldsymbol{\alpha}\)</span>, deux lois <span class="math inline">\(\mathcal{L}_i(X)\)</span> et <span class="math inline">\(\mathcal{L}_{i\prime }(X)\)</span>, parmi les <span class="math inline">\(\boldsymbol{k(k-1})\)</span> comparaisons que nous allons faire, sont significativement différentes si : <span class="math display">\[\left|W_{n_i,n_{i\prime }}-\frac{n_{i}(m_{i,i\prime }+1)}{2}\right|\geqslant {q\prime (k;+\infty;1-\alpha)}\sqrt{\frac{n_{i}n_{i\prime }(m_{i,i\prime }+1)}{24}\left(\displaystyle 1-\frac{\sum_{j=1}^h\left(d_j^3-d_j\right)}{m_{i,i\prime }^3-m_{i,i\prime }}\right)}\]</span> où <span class="math inline">\(q\prime (k;+\infty;1-\alpha)\)</span> est le quantile d’ordre <span class="math inline">\(1-\alpha\)</span> pour la loi du maximum du module studentisé pour <span class="math inline">\(k\)</span> moyennes et <span class="math inline">\(+\infty\)</span> degrés de liberté. Contrairement aux trois autres approches présentées ci-dessous, le test Steel-Dwass-Critchlow-Fligner n’est pas qu’une procédure de comparaisons multiples : c’est une alternative complète au test de Kruskal-Wallis.</p>
</div>
<div id="test-basé-sur-lapplication-de-la-méthode-de-scheffé" class="section level4">
<h4 class="hasAnchor">
<a href="#test-bas%C3%A9-sur-lapplication-de-la-m%C3%A9thode-de-scheff%C3%A9" class="anchor"></a>Test basé sur l’application de la méthode de Scheffé</h4>
<p>Si nous rejetons l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span>, nous nous demandons quelles sont les lois <span class="math inline">\(\mathcal{L}_i(X)\)</span> qui diffèrent. Les formules ci-dessous sont valables en l’absence ou en présence d’ex quo. En l’absence d’ex quo, le terme <span class="math inline">\(1-T/(n_{\bullet}^3-n_{\bullet})\)</span> est égal à 1. Nous décidons qu’au seuil <span class="math inline">\(\boldsymbol{\alpha}\)</span> deux lois <span class="math inline">\(\mathcal{L}_i(X)\)</span> et <span class="math inline">\(\mathcal{L}_{i\prime}(X)\)</span> sont significativement différentes si : <span class="math display">\[\left|\overline{R_{i,\bullet}}-\overline{R_{i\prime,\bullet}}\right|\geqslant \sqrt{\chi^2(k-1;1-\alpha)}\sqrt{\frac{n_{\bullet}(n_{\bullet}+1)}{12}\left(\displaystyle 1-\frac{T}{n_{\bullet}^3-n_{\bullet}}\right)}\sqrt{\frac{1}{n_i}+\frac{1}{n_{i\prime}}},\]</span> où <span class="math inline">\(\chi^2(k-1;1-\alpha)\)</span> est le quantile d’ordre <span class="math inline">\(1-\alpha\)</span> pour la loi du <span class="math inline">\(\chi^2\)</span> à <span class="math inline">\(k-1\)</span> degrés de liberté.</p>
</div>
<div id="test-basé-sur-linégalité-de-bonferroni" class="section level4">
<h4 class="hasAnchor">
<a href="#test-bas%C3%A9-sur-lin%C3%A9galit%C3%A9-de-bonferroni" class="anchor"></a>Test basé sur l’inégalité de Bonferroni</h4>
<p>Nous décidons qu’au seuil global <span class="math inline">\(\boldsymbol{\alpha}\)</span>, deux lois <span class="math inline">\(\mathcal{L}_i(X)\)</span> et <span class="math inline">\({{\mathcal{L}}_{i\prime }}(X)\)</span>, parmi les <span class="math inline">\(\boldsymbol{k(k-1})\)</span> comparaisons que nous allons faire, sont significativement différentes si : <span class="math display">\[\left|\overline{R_{i,\bullet}}-\overline{R_{i\prime,\bullet}}\right|\geqslant u\left(1-\frac{\alpha}{k(k-1)}\right)\sqrt{\frac{n_{\bullet}(n_{\bullet}+1)}{12}\left(\displaystyle 1-\frac{T}{n_{\bullet}^3-n_{\bullet}}\right)}\sqrt{\frac{1}{n_i}+\frac{1}{n_{i\prime }}},\]</span> où <span class="math inline">\(\displaystyle u(1-\alpha/(k(k-1)))\)</span> est le quantile d’ordre <span class="math inline">\(1-\alpha/(k(k-1))\)</span> pour la loi normale centrée-réduite. Il s’agit d’une application des inégalités de Bonferroni. Cette procédure est plus puissante que la précédente. Il existe aussi une variante de ce test basée sur l’inégalité de Holm-Bonferroni : le test de Dunn.</p>
</div>
<div id="test-de-nemenyi" class="section level4">
<h4 class="hasAnchor">
<a href="#test-de-nemenyi" class="anchor"></a>Test de Nemenyi</h4>
<p>Nous décidons qu’au seuil global <span class="math inline">\(\boldsymbol{\alpha}\)</span>, deux lois <span class="math inline">\(\mathcal{L}_i(X)\)</span> et <span class="math inline">\(\mathcal{L}_{i\prime }(X)\)</span>, parmi les <span class="math inline">\(\boldsymbol{k(k-1})\)</span> comparaisons que nous allons faire, sont significativement différentes si : <span class="math display">\[\left|\overline{R_{i,\bullet}}-\overline{R_{i\prime,\bullet}}\right|\geqslant {q(k;+\infty;1-\alpha)}\sqrt{\frac{n_{\bullet}(n_{\bullet}+1)}{12}\left(\displaystyle 1-\frac{T}{n_{\bullet}^3-n_{\bullet}}\right)}\sqrt{\frac{1}{2}\left(\frac{1}{n_i}+\frac{1}{n_{i\prime }}\right)},\]</span> où <span class="math inline">\(q(k;+\infty;1-\alpha)\)</span> est le quantile d’ordre <span class="math inline">\(1-\alpha\)</span> pour la loi de l’étendue studentisée pour <span class="math inline">\(k\)</span> moyennes et <span class="math inline">\(+\infty\)</span> degrés de liberté. Il s’agit d’une procédure analogue à celle de Tukey-Kramer dans le cas paramétrique et valide asymptotiquement. Elle est généralement plus puissante que les deux approches précédentes.</p>
</div>
</div>
</div>
<div id="tests-de-levene-et-de-fligner-dégalité-des-variances" class="section level2">
<h2 class="hasAnchor">
<a href="#tests-de-levene-et-de-fligner-d%C3%A9galit%C3%A9-des-variances" class="anchor"></a>Tests de Levene et de Fligner d’égalité des variances</h2>
<p>Plusieurs tests non paramétriques permettent de tester l’égalité de plusieurs variances. Parmi ceux-ci, les plus utilisés sont le test de Levene et le test de Fligner.</p>
<div id="test-de-fligner" class="section level3">
<h3 class="hasAnchor">
<a href="#test-de-fligner" class="anchor"></a>Test de Fligner</h3>
<div id="hypothèses-testées-6" class="section level4">
<h4 class="hasAnchor">
<a href="#hypoth%C3%A8ses-test%C3%A9es-6" class="anchor"></a>Hypothèses testées</h4>
<p><span class="math inline">\({\mathcal{H}}_{0}:\quad \sigma_1^2=\sigma_2^2= \ldots =\sigma_I^2\)</span> contre <span class="math inline">\({\mathcal{H}}_{1}:\quad\)</span>Les variances <span class="math inline">\(\sigma_i^2\)</span> ne sont pas toutes égales.</p>
</div>
<div id="conditions-dapplication-1" class="section level4">
<h4 class="hasAnchor">
<a href="#conditions-dapplication-1" class="anchor"></a>Conditions d’application</h4>
<p>Les observations sur lesquelles le test est réalisé, doivent être des réalisations indépendantes de variables issues d’une loi continue. Statistique du test La statistique du test n’est pas détaillée ici car sa formule est trop complexe.</p>
</div>
<div id="règle-de-décision-et-conclusion-du-test-8" class="section level4">
<h4 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test-8" class="anchor"></a>Règle de décision et conclusion du test</h4>
<p>Ce test est généralement réalisé à l’aide d’un logiciel de statistique qui nous fournit une <span class="math inline">\(p\)</span>-valeur. Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ p\text{-valeur}\alpha  &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ p\text{-valeur}&gt;\alpha  &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span></p>
</div>
</div>
<div id="test-de-levene" class="section level3">
<h3 class="hasAnchor">
<a href="#test-de-levene" class="anchor"></a>Test de Levene</h3>
<div id="hypothèses-testées-7" class="section level4">
<h4 class="hasAnchor">
<a href="#hypoth%C3%A8ses-test%C3%A9es-7" class="anchor"></a>Hypothèses testées</h4>
<p><span class="math inline">\({\mathcal{H}}_{0}:\quad \sigma_1^2=\sigma_2^2= \ldots =\sigma_I^2\)</span> contre <span class="math inline">\({\mathcal{H}}_{1}:\quad \textrm{Les variances } \sigma_i^2\)</span> ne sont pas toutes égales. Conditions d’application Les observations sur lesquelles le test est réalisé, doivent être des réalisations indépendantes de variables issues d’une loi continue.</p>
</div>
<div id="statistique" class="section level4">
<h4 class="hasAnchor">
<a href="#statistique" class="anchor"></a>Statistique</h4>
<p>La statistique du test n’est pas détaillée ici car sa formule est trop complexe.</p>
</div>
<div id="règle-de-décision-et-conclusion-du-test-9" class="section level4">
<h4 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test-9" class="anchor"></a>Règle de décision et conclusion du test</h4>
<p>Ce test est généralement réalisé à l’aide d’un logiciel de statistique qui nous fournit une <span class="math inline">\(p\)</span>-valeur. Alors nous décidons : <span class="math display">\[\left\{ \begin{matrix}
   si\ p\text{-valeur}\alpha  &amp; {{\mathcal{H}}_{1}}\ est\ vraie,  \\
   si\ p\text{-valeur}&gt;\alpha  &amp; {{\mathcal{H}}_{0}}\ est\ vraie.  \\
\end{matrix} \right.\]</span></p>
</div>
</div>
</div>
<div id="pratique-du-test-de-kruskal-wallis" class="section level2">
<h2 class="hasAnchor">
<a href="#pratique-du-test-de-kruskal-wallis" class="anchor"></a>Pratique du test de Kruskal-Wallis</h2>
<div id="exemple" class="section level3">
<h3 class="hasAnchor">
<a href="#exemple" class="anchor"></a>Exemple</h3>
<p>Nous voulons appliquer le test de Kruskal-Wallis aux données de la Section 9.5.1(c). Nous commençons par mettre en œuvre les tests de Fligner et de Levene aux données de l’application de la Section 9.5.1(c).</p>
</div>
<div id="vérification-des-conditions-fondamentales" class="section level3">
<h3 class="hasAnchor">
<a href="#v%C3%A9rification-des-conditions-fondamentales" class="anchor"></a>Vérification des conditions fondamentales</h3>
<div id="indépendance" class="section level4">
<h4 class="hasAnchor">
<a href="#ind%C3%A9pendance" class="anchor"></a>Indépendance</h4>
<p>L’indépendance des variables observées résulte des conditions expérimentales qui ont été suivies pour réaliser l’expérience : les mesures ont porté sur 90 objets qui ont été choisis au hasard.</p>
</div>
<div id="test-de-fligner-1" class="section level4">
<h4 class="hasAnchor">
<a href="#test-de-fligner-1" class="anchor"></a>Test de Fligner :</h4>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/fligner.test.html">fligner.test</a></span><span class="op">(</span><span class="va">res.model.MV</span>,<span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Fligner-Killeen test of homogeneity of variances</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  res.model.MV and Marque.Valeur$Marque</span>
<span class="co">#&gt; Fligner-Killeen:med chi-squared = 2.5929, df = 2, p-value = 0.2735</span></code></pre></div>
<p>En utilisant un logiciel de statistique, nous calculons la <span class="math inline">\(p\)</span>-valeur qui vaut <span class="math inline">\(0,2735\)</span>. Comme la <span class="math inline">\(p\)</span>-valeur est <span class="math inline">\(&gt;0,05\)</span>, nous décidons, au seuil <span class="math inline">\(\alpha =5\ %,\)</span>que rien ne vient contredire l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span>, c’est-à-dire que l’hypothèse d’homogénéité des variances est vérifiée.</p>
</div>
<div id="test-de-levene-1" class="section level4">
<h4 class="hasAnchor">
<a href="#test-de-levene-1" class="anchor"></a>Test de Levene :</h4>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-forge.r-project.org/projects/car/">car</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/car/man/leveneTest.html">leveneTest</a></span><span class="op">(</span><span class="va">res.model.MV</span>,<span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">)</span>
<span class="co">#&gt; Levene's Test for Homogeneity of Variance (center = median)</span>
<span class="co">#&gt;       Df F value Pr(&gt;F)</span>
<span class="co">#&gt; group  2  1.2809  0.283</span>
<span class="co">#&gt;       87</span></code></pre></div>
<p>En utilisant un logiciel de statistique, nous calculons la <span class="math inline">\(p\)</span>-valeur qui vaut <span class="math inline">\(0,283\)</span>. Comme la <span class="math inline">\(p\)</span>-valeur est <span class="math inline">\(&gt;0,05\)</span>, nous décidons, au seuil <span class="math inline">\(\alpha =5\ %,\)</span>que rien ne vient contredire l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span>, c’est-à-dire que l’hypothèse d’homogénéité des variances est vérifiée. La condition d’homogénéité des variances des variables observées est bien remplie qu’elle soit vérifiée à l’aide du test de Fligner (<span class="math inline">\(p\)</span>-valeur égale à <span class="math inline">\(0,2735\)</span>) ou du test de Levene (<span class="math inline">\(p\)</span>-valeur égale à <span class="math inline">\(0,283\)</span>). Nous sommes en présence d’ex quo, nous devons donc utiliser la statistique de test <span class="math inline">\(KW_{n_{\bullet}}^{\star}\)</span> à la place de la statistique de test <span class="math inline">\(KW_{n_{\bullet}}\)</span>.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw">if</span><span class="op">(</span><span class="op">!</span><span class="op">(</span><span class="st">"PMCMRplus"</span> <span class="op">%in%</span>  <span class="fu"><a href="https://rdrr.io/r/utils/installed.packages.html">installed.packages</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"PMCMRplus"</span><span class="op">)</span><span class="op">}</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">PMCMRplus</span><span class="op">)</span>
<span class="fu">PMCMRplus</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/PMCMRplus/man/kruskalTest.html">kruskalTest</a></span><span class="op">(</span><span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Valeur</span>,<span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">)</span>
<span class="co">#&gt; Warning in kruskalTest.default(Marque.Valeur$Valeur, Marque.Valeur$Marque): Ties</span>
<span class="co">#&gt; are present. Quantiles were corrected for ties.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Kruskal-Wallis test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  Marque.Valeur$Valeur and Marque.Valeur$Marque</span>
<span class="co">#&gt; chi-squared = 53.986, df = 2, p-value = 1.893e-12</span>

<span class="fu"><a href="https://rdrr.io/r/stats/kruskal.test.html">kruskal.test</a></span><span class="op">(</span><span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Valeur</span>,<span class="va">Marque.Valeur</span><span class="op">$</span><span class="va">Marque</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Kruskal-Wallis rank sum test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  Marque.Valeur$Valeur and Marque.Valeur$Marque</span>
<span class="co">#&gt; Kruskal-Wallis chi-squared = 53.986, df = 2, p-value = 1.893e-12</span></code></pre></div>
</div>
</div>
<div id="règle-de-décision-à-laide-dune-valeur-critique" class="section level3">
<h3 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-%C3%A0-laide-dune-valeur-critique" class="anchor"></a>Règle de décision à l’aide d’une valeur critique</h3>
<p>Nous calculons la valeur de <span class="math inline">\(KW_{n_{\bullet}}^{\star}\)</span> sur l’échantillon : <span class="math inline">\(KW_{{{n}_{\bullet }}}^{\star }(obs)=53,986\)</span>. Pour un seuil <span class="math inline">\(\alpha =5\ %,\)</span> la valeur critique d’un Khi-deux à <span class="math inline">\(2\)</span> degrés de liberté, est <span class="math inline">\(c_{0,05}=5,99\)</span>. Comme <span class="math inline">\(KW_{n_{\bullet}}^{\star}(obs) \leqslant c_{0,05}\)</span>, nous décidons de rejeter l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span>, et que l’hypothèse alternative <span class="math inline">\(\mathcal{H}_1\)</span> est vraie. Il y a une influence significative, au seuil <span class="math inline">\(\alpha =5\ %,\)</span>de la marque sur les prix de vente des objets. Le risque associé à cette décision est un risque de première espèce qui vaut <span class="math inline">\(\alpha =5\ %.\)</span></p>
<div id="remarque-8" class="section level4">
<h4 class="hasAnchor">
<a href="#remarque-8" class="anchor"></a>Remarque :</h4>
<p>La valeur non-corrigée de <span class="math inline">\(KW_{n_{\bullet}}(obs)\)</span> est égale à <span class="math inline">\(53,979\)</span>. Nous remarquons la différence apportée par la correction pour prendre en compte les ex quo.</p>
</div>
</div>
<div id="règle-de-décision-à-laide-dune-p-valeur" class="section level3">
<h3 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-%C3%A0-laide-dune-p-valeur" class="anchor"></a>Règle de décision à l’aide d’une p-valeur</h3>
<p>En utilisant un logiciel de statistique, nous calculons la <span class="math inline">\(p\)</span>-valeur du test de Kruskal-Wallis. Il faut bien vérifier qu’elle tient compte des ex quo. Elle vaut dans cas <span class="math inline">\(1,893e-12\)</span>. Comme la <span class="math inline">\(p\)</span>-valeur est <span class="math inline">\(\leqslant 0,05\)</span>, nous décidons, au seuil <span class="math inline">\(\alpha =5\ %,\)</span>de rejeter l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span>, et décidons que l’hypothèse alternative <span class="math inline">\(\mathcal{H}_1\)</span> est vraie. Il y a une influence significative, au seuil <span class="math inline">\(\alpha=5\%\)</span>, <span class="math inline">\(\alpha =5\ %,\)</span>de la marque sur les prix de vente des objets. Le risque associé à cette décision est un risque de première espèce qui vaut <span class="math inline">\(\alpha =5\ %.\)</span></p>
</div>
<div id="comparaisons-multiples-pour-le-test-de-kruskall-wallis" class="section level3">
<h3 class="hasAnchor">
<a href="#comparaisons-multiples-pour-le-test-de-kruskall-wallis" class="anchor"></a>Comparaisons multiples pour le test de Kruskall-Wallis</h3>
<div id="test-basé-sur-la-méthode-de-scheffé" class="section level4">
<h4 class="hasAnchor">
<a href="#test-bas%C3%A9-sur-la-m%C3%A9thode-de-scheff%C3%A9" class="anchor"></a>Test basé sur la méthode de Scheffé</h4>
<p>Les <span class="math inline">\(p\)</span>-valeurs reproduites dans le Tableau 14 indiquent que tous les tests de comparaison deux à deux des distributions des groupes sont significatifs au seuil <span class="math inline">\(\alpha=5\%\)</span>.</p>
<p>Tableau 14 : résultats des comparaisons multiples du test basé sur la méthode de Scheffé.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw">if</span><span class="op">(</span><span class="op">!</span><span class="op">(</span><span class="st">"PMCMR"</span> <span class="op">%in%</span>  <span class="fu"><a href="https://rdrr.io/r/utils/installed.packages.html">installed.packages</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"PMCMR"</span><span class="op">)</span><span class="op">}</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">PMCMR</span><span class="op">)</span>
<span class="fu">PMCMR</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/PMCMR/man/posthoc.kruskal.nemenyi.test.html">posthoc.kruskal.nemenyi.test</a></span><span class="op">(</span><span class="va">Valeur</span><span class="op">~</span><span class="va">Marque</span>, data<span class="op">=</span><span class="va">Marque.Valeur</span>, dist<span class="op">=</span><span class="st">"Chisquare"</span><span class="op">)</span>
<span class="co">#&gt; Warning in posthoc.kruskal.nemenyi.test.default(c(1.5, 1.95, 1.84, 1.08, : Ties</span>
<span class="co">#&gt; are present. Chi-sq was corrected for ties.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pairwise comparisons using Nemenyi-test with Chi-squared    </span>
<span class="co">#&gt;                        approximation for independent samples </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  Valeur by Marque </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     M 1     M 2    </span>
<span class="co">#&gt; M 2 0.00021 -      </span>
<span class="co">#&gt; M 3 2.2e-12 0.00575</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; P value adjustment method: none</span></code></pre></div>
</div>
<div id="test-basé-sur-linégalité-de-bonferroni-1" class="section level4">
<h4 class="hasAnchor">
<a href="#test-bas%C3%A9-sur-lin%C3%A9galit%C3%A9-de-bonferroni-1" class="anchor"></a>Test basé sur l’inégalité de Bonferroni</h4>
<p>Les <span class="math inline">\(p\)</span>-valeurs reproduites dans le Tableau 15 indiquent que tous les tests de comparaison deux à deux des distributions des groupes sont significatifs au seuil <span class="math inline">\(\alpha=5\%\)</span>.</p>
<p>Tableau 15 : résultats des comparaisons multiples du test basé sur l’inégalité de Bonferroni.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">PMCMR</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/PMCMR/man/posthoc.kruskal.dunn.test.html">posthoc.kruskal.dunn.test</a></span><span class="op">(</span><span class="va">Valeur</span><span class="op">~</span><span class="va">Marque</span>, data<span class="op">=</span><span class="va">Marque.Valeur</span>, dist<span class="op">=</span><span class="st">"Tukey"</span>, p.adjust<span class="op">=</span><span class="st">"bonf"</span><span class="op">)</span>
<span class="co">#&gt; Warning in posthoc.kruskal.dunn.test.default(c(1.5, 1.95, 1.84, 1.08, 1.28, :</span>
<span class="co">#&gt; Ties are present. z-quantiles were corrected for ties.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pairwise comparisons using Dunn's-test for multiple </span>
<span class="co">#&gt;                          comparisons of independent samples </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  Valeur by Marque </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     M 1     M 2    </span>
<span class="co">#&gt; M 2 0.00012 -      </span>
<span class="co">#&gt; M 3 7e-13   0.00395</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; P value adjustment method: bonferroni</span></code></pre></div>
</div>
<div id="test-de-dunn" class="section level4">
<h4 class="hasAnchor">
<a href="#test-de-dunn" class="anchor"></a>Test de Dunn</h4>
<p>Les <span class="math inline">\(p\)</span>-valeurs reproduites dans le Tableau 16 indiquent que tous les tests de comparaison deux à deux des distributions des groupes sont significatifs au seuil <span class="math inline">\(\alpha=5\%\)</span>.</p>
<p>Tableau 16 : résultats des comparaisons multiples du test de Dunn.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">PMCMR</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/PMCMR/man/posthoc.kruskal.dunn.test.html">posthoc.kruskal.dunn.test</a></span><span class="op">(</span><span class="va">Valeur</span><span class="op">~</span><span class="va">Marque</span>, data<span class="op">=</span><span class="va">Marque.Valeur</span>, dist<span class="op">=</span><span class="st">"Tukey"</span><span class="op">)</span>
<span class="co">#&gt; Warning in posthoc.kruskal.dunn.test.default(c(1.5, 1.95, 1.84, 1.08, 1.28, :</span>
<span class="co">#&gt; Ties are present. z-quantiles were corrected for ties.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pairwise comparisons using Dunn's-test for multiple </span>
<span class="co">#&gt;                          comparisons of independent samples </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  Valeur by Marque </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     M 1     M 2   </span>
<span class="co">#&gt; M 2 7.7e-05 -     </span>
<span class="co">#&gt; M 3 7.0e-13 0.0013</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; P value adjustment method: holm</span></code></pre></div>
</div>
<div id="test-de-nemeyi-adapté-de-tukey-kramer" class="section level4">
<h4 class="hasAnchor">
<a href="#test-de-nemeyi-adapt%C3%A9-de-tukey-kramer" class="anchor"></a>Test de Nemeyi (adapté de Tukey-Kramer)</h4>
<p>Les <span class="math inline">\(p\)</span>-valeurs reproduites dans le Tableau 17 indiquent que tous les tests de comparaison deux à deux des distributions des groupes sont significatifs au seuil <span class="math inline">\(\alpha=5\%\)</span>.</p>
<p>Tableau 17 : résultats des comparaisons multiples du test de Nemeyi.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">PMCMR</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/PMCMR/man/posthoc.kruskal.nemenyi.test.html">posthoc.kruskal.nemenyi.test</a></span><span class="op">(</span><span class="va">Valeur</span><span class="op">~</span><span class="va">Marque</span>, data<span class="op">=</span><span class="va">Marque.Valeur</span>, dist<span class="op">=</span><span class="st">"Tukey"</span><span class="op">)</span>
<span class="co">#&gt; Warning in posthoc.kruskal.nemenyi.test.default(c(1.5, 1.95, 1.84, 1.08, : Ties</span>
<span class="co">#&gt; are present, p-values are not corrected.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pairwise comparisons using Tukey and Kramer (Nemenyi) test  </span>
<span class="co">#&gt;                    with Tukey-Dist approximation for independent samples </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  Valeur by Marque </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     M 1     M 2    </span>
<span class="co">#&gt; M 2 0.00011 -      </span>
<span class="co">#&gt; M 3 7.2e-13 0.00377</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; P value adjustment method: none</span></code></pre></div>
</div>
</div>
</div>
<div id="test-de-friedman" class="section level2">
<h2 class="hasAnchor">
<a href="#test-de-friedman" class="anchor"></a>Test de Friedman</h2>
<p>Nous nous plaçons dans le cas où les <span class="math inline">\(k\)</span> échantillons utilisés pour tester l’influence d’un facteur à <span class="math inline">\(I\)</span> modalités ne sont pas indépendants.</p>
<table class="table">
<thead><tr class="header">
<th>Individu <span class="math inline">\(\backslash\)</span>
</th>
<th>Facteur 1</th>
<th><span class="math inline">\(\cdots\)</span></th>
<th><span class="math inline">\(I\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(x_{1,1}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(x_{I,1}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(k\)</span></td>
<td><span class="math inline">\(x_{1,k}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(x_{I,k}\)</span></td>
</tr>
</tbody>
</table>
<p>Le tableau ci-dessus présente la situation où il n’y a qu’une seule observation <span class="math inline">\(x_{i,j}\)</span> pour chacune des cellules du tableau. Dans l’éventualité où il y aurait plusieurs observations <span class="math inline">\(x_{i,j,k}\)</span> dans certaines cellules du tableau, nous les remplaçons par leur moyenne <span class="math inline">\(\overline{x_{i,j}}\)</span>.</p>
<table class="table">
<thead><tr class="header">
<th>Individu <span class="math inline">\(\backslash\)</span>
</th>
<th>Facteur 1</th>
<th><span class="math inline">\(\cdots\)</span></th>
<th><span class="math inline">\(I\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(\overline{x_{1,1}}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\overline{x_{I,1}}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td>$</td>
<td><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(k\)</span></td>
<td><span class="math inline">\(\overline{x_{1,k}}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\overline{x_{I,k}}\)</span></td>
</tr>
</tbody>
</table>
<p>Nous construisons alors le tableau des rangs :</p>
<table class="table">
<thead><tr class="header">
<th>Individu <span class="math inline">\(\backslash\)</span> Facteur</th>
<th>1</th>
<th><span class="math inline">\(\cdots\)</span></th>
<th><span class="math inline">\(I\)</span></th>
<th>Totaux</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(r_{1,1}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(r_{I,1}\)</span></td>
<td><span class="math inline">\({I(I+1)}/{2}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\({I(I+1)}/{2}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(k\)</span></td>
<td><span class="math inline">\(r_{1,k}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(r_{I,k}\)</span></td>
<td><span class="math inline">\({I(I+1)}/{2}\)</span></td>
</tr>
<tr class="even">
<td>Totaux</td>
<td><span class="math inline">\(r_{1,\bullet}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(r_{I,\bullet}\)</span></td>
<td><span class="math inline">\(k{I(I+1)}/{2}\)</span></td>
</tr>
</tbody>
</table>
<div id="hypothèses-testées-8" class="section level3">
<h3 class="hasAnchor">
<a href="#hypoth%C3%A8ses-test%C3%A9es-8" class="anchor"></a>Hypothèses testées</h3>
<p><span class="math inline">\({\mathcal{H}}_{0}:\quad\)</span>Les niveaux du facteur ont tous la même influence contre <span class="math inline">\({\mathcal{H}}_{1}:\quad\)</span>Les niveaux du facteur n’ont pas tous la même influence.</p>
</div>
<div id="absence-dex-quo-dans-les-observations-3" class="section level3">
<h3 class="hasAnchor">
<a href="#absence-dex-quo-dans-les-observations-3" class="anchor"></a>Absence d’ex quo dans les observations</h3>
<div id="statistique-de-test-1" class="section level4">
<h4 class="hasAnchor">
<a href="#statistique-de-test-1" class="anchor"></a>Statistique de test</h4>
<p>La statistique de Friedman <span class="math inline">\(F_{k,I}\)</span> est définie par : <span class="math display">\[
F_{k,I}=\frac{12k}{I(I+1)}\sum_{i=1}^I\left(\frac{{R_{i,\bullet}}}{k}-\frac{I+1}{2}\right)^2=\frac{12}{kI(I+1)}\sum_{i=1}^I R_{i,\bullet}^2-3k(I+1).
\]</span> Nous admettons que sous l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span>, les distributions pour chaque individu ne diffèrent que par un paramètre de position, ce que nous ne pouvons qu’évaluer graphiquement.</p>
</div>
<div id="règle-de-décision-et-conclusion-du-test-10" class="section level4">
<h4 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test-10" class="anchor"></a>Règle de décision et conclusion du test</h4>
<ul>
<li>Pour de petites valeurs de <span class="math inline">\(k\)</span>, nous utilisons une table spécifique au test de Friedman. Nous pouvons également utiliser une table du coefficient de concordance <span class="math inline">\(W_{k,I}\)</span> de Kendall car il existe un lien entre le coefficient de concordance <span class="math inline">\(W_{k,I}\)</span> et la statistique de Friedman <span class="math inline">\(F_{k,I}=k(I-1)W_{k,I}\)</span>.</li>
<li>Pour des valeurs de <span class="math inline">\(k\)</span> assez grandes, nous utilisons l’approximation asymptotique suivante <span class="math inline">\(F_{k,I}\approx\chi^2_{I-1}\)</span> et nous concluons grâce à la lecture d’une table de la loi du <span class="math inline">\(\chi^2\)</span> à <span class="math inline">\(I-1\)</span> degrés de liberté. Nous rejetons l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> si la valeur prise par <span class="math inline">\(F_{k,I}\)</span> est trop grande.</li>
</ul>
</div>
</div>
<div id="présence-dex-quo-dans-les-observations-méthode-des-rangs-moyens" class="section level3">
<h3 class="hasAnchor">
<a href="#pr%C3%A9sence-dex-quo-dans-les-observations-m%C3%A9thode-des-rangs-moyens" class="anchor"></a>Présence d’ex quo dans les observations : Méthode des rangs moyens</h3>
<p>Dans chaque classement présentant des ex quo, nous attribuons à chacun de ceux-ci le rang moyen du groupe d’ex quo auquel ils appartiennent et qui n’est pas nécessairement un entier. Lorsque le classement numéro <span class="math inline">\(m\)</span> a <span class="math inline">\(h_m\)</span> groupes d’ex quo, nous lui attribuons la somme <span class="math inline">\(T_m = \displaystyle\sum_{l=1}^{h_m}\left(t_{l,m}^3-t_{l,m}\right)\)</span> où <span class="math inline">\(t_{l,m}\)</span> désigne le nombre d’éléments du <span class="math inline">\(l\)</span>-ème de ces <span class="math inline">\(h_m\)</span> groupes. S’il n’y a pas d’ex quo, nous avons évidemment <span class="math inline">\(T_m=0\)</span> puisque la répartition des <span class="math inline">\(I\)</span> entiers du classement en classes de nombres égaux donne <span class="math inline">\(h_m=I\)</span> et <span class="math inline">\(t_{l,m}=1\)</span> pour tout <span class="math inline">\(l\)</span>. Alors la statistique de Friedman corrigée est définie par : <span class="math display">\[
F_{k,I}^{\star }=\frac{12k(I-1)}{\left( {{I}^{3}}-I \right)-\frac{1}{k}\sum\limits_{m=1}^{k}{{{T}_{m}}}}\sum\limits_{l=1}^{I}{{{\left( \frac{{{r}_{l,\bullet }}}{k}-\frac{I+1}{2} \right)}^{2}}}=\frac{{{F}_{k,I}}}{1-\frac{1}{({{I}^{3}}-I)}\frac{1}{k}\sum\limits_{m=1}^{k}{{{T}_{m}}}}\cdot
\]</span></p>
</div>
</div>
</div>
<div id="compléments--comment-améliorer-un-estimateur" class="section level1">
<h1 class="hasAnchor">
<a href="#compl%C3%A9ments--comment-am%C3%A9liorer-un-estimateur" class="anchor"></a>Compléments. Comment améliorer un estimateur ?</h1>
<div id="statistiques-exhaustives--famille-exponentielle" class="section level2">
<h2 class="hasAnchor">
<a href="#statistiques-exhaustives--famille-exponentielle" class="anchor"></a>Statistiques exhaustives. Famille exponentielle</h2>
<div id="définition-37-statistique-exhaustive" class="section level3">
<h3 class="hasAnchor">
<a href="#d%C3%A9finition-37-statistique-exhaustive" class="anchor"></a>Définition 37 Statistique exhaustive</h3>
<p>Soit le modèle statistique <span class="math inline">\((D_X, \mathbb{P}_{\theta})\)</span>, où <span class="math inline">\(D_X\)</span> est l’ensemble des valeurs de la variable aléatoire <span class="math inline">\(X\)</span> et où <span class="math inline">\(\mathbb{P}_{\theta}\)</span> est la loi de probabilité sur <span class="math inline">\(D_X\)</span> dont la densité (ou la probabilité) au point <span class="math inline">\(x\)</span> est <span class="math inline">\(f_X(x,\theta)\)</span>. <span class="math inline">\(S\)</span> est une statistique exhaustive si la loi conditionnelle de <span class="math inline">\(X\)</span> sachant <span class="math inline">\(S(x)=s\)</span> est indépendante du paramètre <span class="math inline">\(\theta\)</span>, soit <span class="math inline">\(\mathbb{P}\left(X|S(x)=s\right)\)</span> indépendante de <span class="math inline">\(\theta\)</span>.</p>
</div>
<div id="remarque-9" class="section level3">
<h3 class="hasAnchor">
<a href="#remarque-9" class="anchor"></a>Remarque :</h3>
<p>Cela signifie que la donnée de <span class="math inline">\(S\)</span> seule renseigne complètement sur la valeur du paramètre <span class="math inline">\(\theta\)</span> et que les valeurs de <span class="math inline">\(X\)</span> n’apportent aucune information supplémentaire.</p>
</div>
<div id="théorème-principe-de-factorisation-" class="section level3">
<h3 class="hasAnchor">
<a href="#th%C3%A9or%C3%A8me-principe-de-factorisation-" class="anchor"></a>Théorème : Principe de factorisation.</h3>
<p>Soit le modèle statistique <span class="math inline">\((D_X, \mathbb{P}_{\theta})\)</span> et <span class="math inline">\(S\)</span> une statistique. <span class="math inline">\(S\)</span> est une statistique exhaustive si et seulement si <span class="math inline">\(f_X(x,\theta)\)</span> se met sous la forme : <span class="math display">\[
f_X(x,\theta)=g_X(x)\times h_S(S(x),\theta),
\]</span> où <span class="math inline">\(g_X(x)\geqslant 0\)</span> et où <span class="math inline">\(h_S\)</span> est la densité de la statistique <span class="math inline">\(S\)</span>.</p>
</div>
<div id="remarque-10" class="section level3">
<h3 class="hasAnchor">
<a href="#remarque-10" class="anchor"></a>Remarque :</h3>
<p>Le principe de factorisation fournit un moyen de reconnaître si une statistique est exhaustive, mais ne permet pas de la construire ou même de savoir s’il en existe une. La famille exponentielle, parfois dite de Darmois ou de Koopman, est fondamentale en statistique.</p>
</div>
<div id="définition-38-modèle-exponentiel" class="section level3">
<h3 class="hasAnchor">
<a href="#d%C3%A9finition-38-mod%C3%A8le-exponentiel" class="anchor"></a>Définition 38 Modèle exponentiel</h3>
<p>Un modèle statistique <span class="math inline">\((D_X, \mathbb{P}_{\theta})\)</span> est exponentiel s’il existe une mesure positive <span class="math inline">\(\mu\)</span> <span class="math inline">\(\sigma-\)</span>finie, un entier naturel <span class="math inline">\(r\)</span>, des fonctions réelles mesurables <span class="math inline">\(x \rightarrow h(x)&gt;0\)</span>, <span class="math inline">\(x \rightarrow T_1(x),\ldots,x \rightarrow T_r(x)\)</span> et des fonctions réelles <span class="math inline">\(\theta \rightarrow c(\theta)\)</span> et <span class="math inline">\(\theta \rightarrow \alpha_1(\theta),\ldots,\theta \rightarrow \alpha_r(\theta)\)</span> telles que <span class="math inline">\(\mathbb{P}_{\theta}\)</span> admette pour densité par rapport à <span class="math inline">\(\mu\)</span> : <span class="math display">\[
f_X(x,\theta)=c(\theta)h(x)\exp\left(\sum_{j=1}^r\alpha_j(\theta)T_j(x)\right).
\]</span> La famille des probabilités <span class="math inline">\((\mathbb{P}_{\theta}, \theta \in \Theta)\)</span> est appelée famille exponentielle. <span class="math inline">\(T=(T_1,\ldots,T_r)\)</span> est appelée statistique privilégiée du modèle.</p>
</div>
<div id="théorème-de-darmois-" class="section level3">
<h3 class="hasAnchor">
<a href="#th%C3%A9or%C3%A8me-de-darmois-" class="anchor"></a>Théorème de Darmois.</h3>
<p>Soit une variable aléatoire <span class="math inline">\(X\)</span> dont le domaine de définition ne dépend pas de <span class="math inline">\(\theta\)</span>. Une condition nécessaire et suffisante pour que l’échantillon <span class="math inline">\((X_1,\dots,X_n)\)</span> admette une statistique exhaustive est que la forme de la densité soit : <span class="math display">\[
f(x,\theta)=\exp\left(\beta(\theta)+b(x)+\sum_{j=1}^r\alpha_j(\theta)a_j(x)\right)\quad\mbox{(famille exponentielle).}
\]</span> Si la densité est de cette forme alors <span class="math inline">\(T=(\sum_{i=1}^n a_1(X_i),\ldots,\sum_{i=1}^n a_r(X_i))\)</span> est une statistique exhaustive particulière.</p>
</div>
<div id="remarques-8" class="section level3">
<h3 class="hasAnchor">
<a href="#remarques-8" class="anchor"></a>Remarques :</h3>
<ol style="list-style-type: decimal">
<li>Si le domaine de définition de <span class="math inline">\(X\)</span> dépend de <span class="math inline">\(\theta\)</span>, le théorème de Darmois ne s’applique pas, ce qui n’empêche pas de trouver dans certains cas des statistiques exhaustives.</li>
<li>La plupart des lois usuelles, loi de Poisson, loi de Laplace-Gauss, lois <span class="math inline">\(\gamma\)</span> sont de la forme exponentielle.</li>
<li>Toute fonction injective d’une statistique exhaustive est encore exhaustive.</li>
</ol>
</div>
</div>
<div id="estimateur-sans-biais-de-variance-minimale" class="section level2">
<h2 class="hasAnchor">
<a href="#estimateur-sans-biais-de-variance-minimale" class="anchor"></a>Estimateur sans biais de variance minimale</h2>
<div id="théorème" class="section level3">
<h3 class="hasAnchor">
<a href="#th%C3%A9or%C3%A8me" class="anchor"></a>Théorème :</h3>
<p>S’il existe un estimateur de <span class="math inline">\(\theta\)</span> sans biais, de variance minimale, il est unique presque sûrement.</p>
</div>
<div id="théorème-de-rao-blackwell" class="section level3">
<h3 class="hasAnchor">
<a href="#th%C3%A9or%C3%A8me-de-rao-blackwell" class="anchor"></a>Théorème de Rao-Blackwell :</h3>
<p>Soit <span class="math inline">\(T\)</span> un estimateur sans biais de <span class="math inline">\(\theta\)</span>, <span class="math inline">\(S\)</span> une statistique exhaustive de <span class="math inline">\(\theta\)</span>, <span class="math inline">\(h(S)=\mathbb{E}(T|S=s)\)</span> est un estimateur sans biais pour <span class="math inline">\(\theta\)</span>, préférable au sens large à <span class="math inline">\(T\)</span>, c’est-à-dire tel que <span class="math inline">\(\mathrm{Var}(T)\geqslant \mathrm{Var}(h(S))\)</span>, avec <span class="math inline">\(h\)</span> indépendant de <span class="math inline">\(\theta\)</span>.</p>
</div>
<div id="propriété" class="section level3">
<h3 class="hasAnchor">
<a href="#propri%C3%A9t%C3%A9" class="anchor"></a>Propriété :</h3>
<p>S’il existe une statistique exhaustive <span class="math inline">\(U\)</span>, alors l’estimateur sans biais <span class="math inline">\(T\)</span> de <span class="math inline">\(\theta\)</span> de variance minimale ne dépend que de <span class="math inline">\(U\)</span>.</p>
</div>
<div id="définition-39-statistique-complète" class="section level3">
<h3 class="hasAnchor">
<a href="#d%C3%A9finition-39-statistique-compl%C3%A8te" class="anchor"></a>Définition 39 Statistique complète</h3>
<p>Si <span class="math inline">\(X\)</span> est une variable aléatoire à valeurs dans <span class="math inline">\(D_X\)</span> de loi de probabilité <span class="math inline">\(\mathbb{P}_{\theta}\)</span>, la statistique <span class="math inline">\(\boldsymbol{U}\)</span> est complète ou la famille <span class="math inline">\((D_X,\mathbb{P}_{\theta})\)</span>} est complète, si : <span class="math display">\[
\forall \theta \in \Theta ,\ \mathbb{E}\left( h(U) \right)=0\Rightarrow h=0\quad \text{presque}\ \text{sûrement}.
\]</span></p>
</div>
<div id="propriété-1" class="section level3">
<h3 class="hasAnchor">
<a href="#propri%C3%A9t%C3%A9-1" class="anchor"></a>Propriété :</h3>
<p>La statistique exhaustive d’une famille exponentielle est complète.</p>
</div>
<div id="théorème-de-lehmann-scheffe" class="section level3">
<h3 class="hasAnchor">
<a href="#th%C3%A9or%C3%A8me-de-lehmann-scheffe" class="anchor"></a>Théorème de Lehmann-Scheffe :</h3>
<p>Si <span class="math inline">\(T^*\)</span> est un estimateur sans biais de <span class="math inline">\(\theta\)</span>, dépendant d’une statistique exhaustive complète <span class="math inline">\(U\)</span>, alors <span class="math inline">\(T^*\)</span> est l’unique estimateur sans biais de variance minimale de <span class="math inline">\(\theta\)</span>. En particulier, si nous disposons déjà de <span class="math inline">\(T\)</span>, estimateur sans biais de <span class="math inline">\(\theta\)</span>, alors <span class="math inline">\(T^*=\mathbb{E}(T|U)\)</span>.</p>
</div>
</div>
</div>
<div id="compléments--tests-paramétriques-" class="section level1">
<h1 class="hasAnchor">
<a href="#compl%C3%A9ments--tests-param%C3%A9triques-" class="anchor"></a>Compléments. Tests paramétriques.</h1>
<div id="comparaison-de-deux-espérances-de-lois-quelconques-de-variances-inconnues" class="section level2">
<h2 class="hasAnchor">
<a href="#comparaison-de-deux-esp%C3%A9rances-de-lois-quelconques-de-variances-inconnues" class="anchor"></a>Comparaison de deux espérances de lois quelconques de variances inconnues</h2>
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire d’espérance égale à <span class="math inline">\(\mu_1\)</span> et d’écart-type égal à <span class="math inline">\(\sigma_1\)</span> et <span class="math inline">\(Y\)</span> une variable aléatoire d’espérance égale à <span class="math inline">\(\mu_2\)</span> et d’écart-type égal à <span class="math inline">\(\sigma_2\)</span> avec <span class="math inline">\(\sigma_1\)</span> et <span class="math inline">\(\sigma_2\)</span> inconnus.</p>
<div id="hypothèses-testées-9" class="section level3">
<h3 class="hasAnchor">
<a href="#hypoth%C3%A8ses-test%C3%A9es-9" class="anchor"></a>Hypothèses testées</h3>
<p>Ce sont les mêmes hypothèses que dans la première section.</p>
</div>
<div id="conditions-dapplication-du-test-1" class="section level3">
<h3 class="hasAnchor">
<a href="#conditions-dapplication-du-test-1" class="anchor"></a>Conditions d’application du test</h3>
<p>Les effectifs <span class="math inline">\(n_1\)</span> et <span class="math inline">\(n_2\)</span> sont tous les deux supérieurs à 30.</p>
</div>
<div id="statistique-du-test-7" class="section level3">
<h3 class="hasAnchor">
<a href="#statistique-du-test-7" class="anchor"></a>Statistique du test</h3>
<p>La variable aléatoire <span class="math inline">\(\zeta_{n_1,n_2}=\frac{\displaystyle{\widehat{\mu}_{n_1}-\widehat{\mu}_{n_2}}}{\sqrt{\displaystyle\frac{S_{n_1}^2}{n_1-1}+\frac{S_{n_2}^2}{n_2-1}}}\)</span> suit approximativement la loi normale <span class="math inline">\(\mathcal{N}(0;1)\)</span>.</p>
</div>
<div id="règle-de-décision-et-conclusion-du-test-11" class="section level3">
<h3 class="hasAnchor">
<a href="#r%C3%A8gle-de-d%C3%A9cision-et-conclusion-du-test-11" class="anchor"></a>Règle de décision et conclusion du test</h3>
<p>La valeur critique du test, notée <span class="math inline">\(c_{\alpha}\)</span>, est lue dans une table de la loi normale centrée-réduite.</p>
<p>Si la valeur absolue de la valeur de la statistique calculée sur l’échantillon, notée <span class="math inline">\(\zeta_{n_1,n_2}(obs)\)</span>, est supérieure ou égale à <span class="math inline">\(c_{\alpha}\)</span>, alors le test est significatif. Nous rejetons <span class="math inline">\(\mathcal{H}_0\)</span> et nous décidons que <span class="math inline">\(\mathcal{H}_1\)</span> est vraie avec un risque de première espèce <span class="math inline">\(\alpha\)</span>.</p>
<p>Si la valeur absolue de la valeur de la statistique calculée sur l’échantillon, notée <span class="math inline">\(\zeta_{n_1,n_2}(obs)\)</span>, est strictement inférieure à <span class="math inline">\(c_{\alpha}\)</span>, alors le test n’est pas significatif. Nous conservons <span class="math inline">\(\mathcal{H}_0\)</span> avec un risque de deuxième espèce <span class="math inline">\(\beta\)</span>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Frederic Bertrand, Myriam Maumy.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
